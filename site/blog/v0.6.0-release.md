---
title: "Probe v0.6.0 Release: Enhanced AI Integration and Code Editing Capabilities"
description: Announcing Probe v0.6.0 with the new implement tool, enhanced GitHub Actions integration, crates.io publishing, and major improvements for AI coding assistants.
layout: doc
date: 2025-07-17
tags:
  - release
  - v0.6.0
  - ai-integration
  - code-editing
  - github-actions
  - crates-io
---

# Probe v0.6.0: Enhanced AI Integration and Code Editing Capabilities

We're excited to announce the release of **Probe v0.6.0**, a major update that significantly enhances AI integration capabilities and introduces powerful new features for AI coding assistants. This release represents months of development focused on making Probe the most comprehensive tool for AI-powered code understanding and manipulation.

## 🚀 What's New in v0.6.0

### Revolutionary Implement Tool

The headline feature of v0.6.0 is the new **[implement tool](/cli-mode#code-editing---allow-edit)**, which enables AI assistants to directly edit code files during conversations. This breakthrough capability transforms Probe from a read-only code search tool into a full-featured AI coding companion.

**Key capabilities:**
- **Direct Code Editing**: AI assistants can now modify files directly through Probe
- **Aider Integration**: Leverages the powerful Aider tool for sophisticated code modifications
- **Safe Execution**: Configurable via `allow_edit` flag with proper permission controls - see [GitHub Actions configuration](/integrations/github-actions#code-modification-options)
- **Context-Aware**: Combines code search with intelligent editing suggestions

```javascript
// Example: AI can now implement features directly
const result = await implementTool({
  instruction: "Add error handling to the login function",
  files: ["src/auth.js"],
  context: searchResults
});
```

### Enhanced GitHub Actions Integration

v0.6.0 introduces several powerful GitHub Actions enhancements that make Probe even more valuable for team workflows:

#### Allow Suggestions Feature
- **Reviewdog Integration**: New `allow_suggestions` flag enables AI-powered code suggestions - see [GitHub Actions Integration](/integrations/github-actions#suggested-changes-allow_suggestions-true---recommended)
- **Pull Request Reviews**: Automatic code review suggestions on PRs
- **Configurable Workflows**: Fine-grained control over when suggestions are enabled

#### Failure Tagging and Monitoring
- **Automatic Tagging**: Failed Probe runs are automatically tagged for easy tracking
- **Better Debugging**: Enhanced error reporting and logging
- **Workflow Reliability**: Improved stability across different repository configurations

#### OpenTelemetry Tracing
- **Complete Observability**: Full OpenTelemetry integration for monitoring AI model interactions - see [AI Chat Tracing](/ai-chat#opentelemetry-tracing)
- **Performance Insights**: Track response times, token usage, and throughput
- **GitHub Actions Integration**: Automatic trace collection with artifact uploads - see [GitHub Actions Tracing](/integrations/github-actions#opentelemetry-tracing)
- **Multiple Export Options**: File-based tracing for offline analysis and remote tracing to collectors

#### New Specialized Workflows
- **probe-engineer.yml**: Dedicated workflow for engineering-focused AI assistance - see [AI Engineer example](/integrations/github-actions#example-2-ai-engineer-code-editing-enabled)
- **Enhanced probe.yml**: Improved main workflow with better error handling
- **Integration Testing**: Comprehensive test coverage for GitHub Actions

### Docker Integration & Containerization

v0.6.0 introduces comprehensive Docker support, making Probe deployment and integration easier than ever:

#### Official Docker Images
- **Pre-built images**: Available on Docker Hub with automatic CI/CD publishing
  - `probelabs/probe` - CLI tool for code search and analysis
  - `probelabs/probe-chat` - AI-powered chat interface
- **Multi-platform support**: Images built for linux/amd64 and linux/arm64
- **Semantic versioning**: Tagged releases with `latest`, `X.Y.Z`, `X.Y`, and `X` tags

```bash
# Quick start with Docker
docker pull probelabs/probe:latest
docker run --rm -v $(pwd):/workspace probelabs/probe search "function" /workspace

# AI chat interface
docker run --rm -e ANTHROPIC_API_KEY=your_key -p 3000:3000 probelabs/probe-chat --web
```

#### Production-Ready Features
- **Security best practices**: Non-root execution, minimal base images
- **Health checks**: Built-in health monitoring for both CLI and web interfaces
- **Docker Compose**: Complete development environment setup
- **OCI compliance**: Industry-standard labels and metadata

#### CI/CD Integration
Docker images are automatically built and published as part of the release workflow, ensuring consistency and reliability:

```yaml
# Example CI/CD usage
- name: Analyze Code Structure
  run: |
    docker run --rm -v ${{ github.workspace }}:/workspace \
      probelabs/probe search "TODO|FIXME" /workspace --format json
```

### Crates.io Publishing

Probe is now available as a **Rust library** on crates.io, opening up new integration possibilities:

```toml
[dependencies]
probe = "0.6.0"
```

**Benefits:**
- **Native Rust Integration**: Use Probe directly in Rust applications
- **Library API**: Clean, documented API for programmatic access
- **Automated Publishing**: Seamless releases synchronized with GitHub

### OpenTelemetry Tracing and Observability

v0.6.0 introduces comprehensive **OpenTelemetry tracing** capabilities, providing unprecedented visibility into AI model interactions:

#### Complete AI Model Monitoring
```bash
# Enable file-based tracing
npx @probelabs/probe-chat@latest --trace-file ./traces.jsonl

# Enable remote tracing to Jaeger
npx @probelabs/probe-chat@latest --trace-remote http://localhost:4318/v1/traces
```

#### Rich Telemetry Data
Every AI interaction is captured with detailed metrics:

```json
{
  "name": "ai.generateText",
  "attributes": {
    "ai.model.id": "claude-3-7-sonnet-20250219",
    "ai.model.provider": "anthropic",
    "ai.usage.prompt_tokens": "245",
    "ai.usage.completion_tokens": "156",
    "ai.usage.total_tokens": "401"
  },
  "events": [
    {
      "name": "ai.request.start",
      "attributes": {
        "ai.request.messages": "[{\"role\":\"user\",\"content\":\"How does auth work?\"}]"
      }
    },
    {
      "name": "ai.response.complete",
      "attributes": {
        "ai.response.finish_reason": "stop"
      }
    }
  ]
}
```

#### GitHub Actions Integration
Automatic trace collection in CI/CD workflows:

```yaml
# Enhanced GitHub Actions with tracing
- uses: probelabs/probe@v0.6.0
  with:
    enable_tracing: true    # Enable tracing
    allow_suggestions: true # Enable suggestions
  secrets:
    TRACING_URL: ${{ secrets.TRACING_URL }}  # Optional remote endpoint
```

**Benefits:**
- **Performance Monitoring**: Track AI response times and optimize workflows
- **Cost Management**: Monitor token usage and optimize AI interactions
- **Debugging**: Identify failed requests and troubleshoot issues
- **Analytics**: Understand usage patterns and model performance

### AI Chat and MCP Improvements

#### Revolutionary Chat History and Session Persistence
One of the most requested features is now here: **persistent chat sessions** that transform the chat interface from ephemeral conversations into a powerful knowledge management system.

**Key Features:**
- **Persistent Sessions**: All chat sessions are automatically saved to `~/.probe/sessions/` and survive browser refreshes and server restarts
- **History Navigation**: Interactive dropdown with session previews, timestamps, and message counts
- **URL-based Session Sharing**: Share and bookmark conversations with unique URLs (`/chat/session-id`)
- **Cross-platform Storage**: Seamless storage across Unix (`~/.probe/sessions/`) and Windows (`%LOCALAPPDATA%\probe`) systems
- **Enhanced UI**: Always-visible header with clickable logo and improved navigation experience

```bash
# Session storage is automatic - no configuration needed
npx @probelabs/probe-chat@latest --web

# Sessions are stored in:
# Unix/Linux/macOS: ~/.probe/sessions/
# Windows: %LOCALAPPDATA%\probe\sessions\
```

This transforms the chat interface from a tool for one-off questions into a comprehensive knowledge base where you can:
- **Resume previous conversations** exactly where you left off
- **Navigate between related sessions** using the history dropdown
- **Share specific conversations** with team members via URLs
- **Build knowledge over time** with persistent conversation history

#### Enhanced Chat Experience
- **Configurable Iterations**: Control AI conversation length with `MAX_TOOL_ITERATIONS` - see [AI Chat configuration](/ai-chat#configuration)
- **Better Tool Support**: New file listing and search capabilities
- **Improved Session Management**: Enhanced token tracking and conversation history

#### MCP Protocol Updates
- **Mandatory Path Parameters**: Improved tool definitions with required parameters - see [MCP Server tools](/mcp-server#available-tools)
- **Better Error Handling**: More informative error messages and validation
- **Standardized Interfaces**: Consistent tool behavior across all MCP implementations - see [MCP Integration guide](/mcp-integration)

## 🔧 Technical Improvements

### Cross-Platform Compatibility
- **Windows Support**: Significant improvements for Windows users
- **Binary Management**: Enhanced download and path resolution
- **Permission Handling**: Fixed binary permission issues across platforms

### Developer Experience
- **Enhanced Documentation**: Comprehensive guides for new features
- **Better Examples**: Real-world use cases and implementation patterns
- **Improved Testing**: Expanded test coverage and CI/CD improvements

### Ripgrep Integration: Revolutionary Search Performance

One of the most significant technical improvements in v0.6.0 is the **native integration of the ripgrep Rust library**, delivering substantial performance gains across all search operations.

#### Performance Benchmarks

The ripgrep integration delivers measurable performance improvements across key operations:

- **File Searching**: **13% faster** (249ms → 217ms average)
- **File I/O Operations**: **33% faster** (303ms → 202ms average)  
- **AST Parsing**: **32% faster** tree parsing through optimized I/O
- **Memory Efficiency**: Significantly reduced memory usage for large codebases

#### Technical Implementation

**RipgrepSearcher Module**: A new dedicated searcher implementation that leverages ripgrep's advanced capabilities:

```rust
pub struct RipgrepSearcher {
    patterns: Vec<String>,
    enable_simd: bool,
    debug_mode: bool,
    io_config: IOConfig,
    regex_set: RegexSet,
}
```

**Key Technical Improvements:**

- **Pre-compiled RegexSet**: Eliminates redundant regex compilation by compiling patterns once instead of per-file
- **SIMD Optimizations**: Leverages SIMD instructions for faster pattern matching where hardware supports it
- **Memory Mapping**: Intelligent memory mapping with fallback for optimal file access patterns
- **Advanced Encoding Detection**: Better handling of different file encodings and compression formats
- **Streaming I/O**: Optimized streaming for large files to reduce memory footprint

#### Bug Fixes and Reliability

- **Fixed Timing Measurement**: Corrected a bug where "Uncovered lines" timing was double-counting "term matching" time
- **Deterministic Results**: All search results are now consistent across runs, eliminating non-deterministic behavior
- **Better Error Handling**: Enhanced error recovery and reporting for edge cases

#### Real-World Impact

For typical codebases, users will experience:
- **Faster Initial Searches**: Reduced time to first results
- **Improved Responsiveness**: More responsive AI interactions during code analysis
- **Better Resource Usage**: Lower memory consumption, especially for large repositories
- **Consistent Performance**: Predictable performance characteristics across different file types and sizes

This integration represents a fundamental improvement to Probe's core search engine, making it significantly more efficient for AI-powered code analysis workflows.

### Performance and Reliability
- **Memory Efficiency**: Reduced memory usage for large codebases through ripgrep integration
- **Error Recovery**: Better handling of edge cases and error conditions

## 📈 Impact on AI Coding Workflows

v0.6.0 represents a paradigm shift in how AI assistants interact with codebases:

### Before v0.6.0: Read-Only Analysis
```
AI: "I can see the bug in line 42, but you'll need to fix it manually"
```

### After v0.6.0: Full Code Interaction
```
AI: "I found the bug in line 42. Let me fix it for you..."
[Automatically implements the fix]
AI: "Fixed! The error handling now properly catches network timeouts."
```

### Real-World Use Cases

#### Automated Code Reviews
```yaml
# .github/workflows/ai-review.yml
- uses: probelabs/probe@v0.6.0
  with:
    allow_suggestions: true
    prompt: "code-review"
```

#### Interactive Development
```bash
# Start an AI coding session with tracing
npx @probelabs/probe-chat@latest --allow-edit --trace-file ./session-traces.jsonl
```

#### Knowledge Management with Chat History
```bash
# Start a web session that automatically persists
npx @probelabs/probe-chat@latest --web --port 8080

# Your conversations are automatically saved and can be resumed:
# - Browse previous sessions via the history dropdown
# - Share specific conversations: http://localhost:8080/chat/abc123-session-id
# - Sessions persist across server restarts and browser refreshes
```

#### Custom AI Tools
```rust
// Integrate Probe into your Rust application
use probe::{search, extract, implement};

let results = search("authentication logic").await?;
let code = extract(&results[0]).await?;
implement("add rate limiting", &code).await?;
```

#### AI Performance Monitoring
```bash
# Monitor AI interactions with remote tracing
npx @probelabs/probe-chat@latest --trace-remote http://jaeger:4318/v1/traces

# Analyze performance offline
npx @probelabs/probe-chat@latest --trace-file ./performance-traces.jsonl
cat performance-traces.jsonl | jq '.events[]? | select(.name == "ai.response.complete")'
```

## 🛠 Migration Guide

### For GitHub Actions Users
Update your workflows to take advantage of new features:

```yaml
# Old configuration
- uses: probelabs/probe@v0.5.0

# New configuration with v0.6.0 features
- uses: probelabs/probe@v0.6.0
  with:
    allow_edit: true          # Enable code editing
    allow_suggestions: true   # Enable PR suggestions
    enable_tracing: true      # Enable OpenTelemetry tracing
    prompt: "architect"       # Use specialized prompts
```

### For API Users
The core API remains backward compatible, with new optional parameters:

```javascript
// Enhanced search with editing capabilities
const probe = new Probe({
  allowEdit: true,  // New in v0.6.0
  maxIterations: 50 // Configurable iterations
});
```

### For Rust Developers
Add Probe as a dependency to access the new library API:

```toml
[dependencies]
probe = "0.6.0"
```

## 🔮 Looking Ahead

v0.6.0 lays the foundation for even more exciting developments:

- **Advanced AI Agents**: Multi-step reasoning and planning capabilities
- **IDE Integrations**: Native support for popular code editors
- **Team Collaboration**: Enhanced features for team-based AI workflows
- **Custom Models**: Support for specialized domain-specific AI models

## 📚 Resources

- **[Full Changelog](/changelog)**: Complete list of changes and improvements
- **[GitHub Repository](https://github.com/probelabs/probe)**: Source code and issue tracking
- **[Documentation](/quick-start)**: Updated guides and API reference
- **[NPM Package](https://www.npmjs.com/package/@probelabs/probe)**: Node.js integration
- **[Crates.io Package](https://crates.io/crates/probe)**: Rust library
- **[Discord Community](https://discord.gg/hBN4UsTZ)**: Join the discussion

## 🙏 Acknowledgments

This release wouldn't have been possible without the contributions from our amazing community. Special thanks to all the developers who provided feedback, reported issues, and contributed code improvements.

We're particularly grateful for the extensive testing and feedback that helped shape the implement tool and GitHub Actions enhancements.

## 🚀 Get Started Today

Ready to experience the future of AI-powered code interaction? Get started with Probe v0.6.0:

```bash
# Install the latest version
npm install -g @probelabs/probe-chat@latest

# Or use directly
npx @probelabs/probe-chat@latest --allow-edit

# For Rust projects
cargo add probe
```

Join thousands of developers who are already using Probe to supercharge their AI coding workflows. The future of software development is here, and it's more intelligent than ever.

---

*Have questions or feedback about v0.6.0? Join our [Discord community](https://discord.gg/hBN4UsTZ) or [open an issue](https://github.com/probelabs/probe/issues) on GitHub. We'd love to hear from you!*
