//! SQLite backend implementation using Turso
//!
//! This module provides a SQLite-based implementation of the DatabaseBackend trait
//! using Turso for fast, local database operations. It's designed to be a drop-in
//! replacement for DuckDB with much faster compilation times.

use anyhow::Result;
use async_trait::async_trait;
use std::collections::HashMap;
use std::hash::{Hash, Hasher};
use std::path::{Path, PathBuf};
use std::sync::Arc;
use tokio::sync::{Mutex, RwLock};
use tracing::{debug, error, info, warn};
use turso::{Builder, Connection, Database};

use crate::database::{
    migrations::{all_migrations, MigrationRunner},
    AnalysisProgress, CallDirection, DatabaseBackend, DatabaseConfig, DatabaseError, DatabaseStats,
    DatabaseTree, Edge, EdgeInterpretation, EdgeRelation, FileVersion, GraphPath, SymbolState, Workspace,
};
use crate::protocol::{CallHierarchyResult, Location};

/// SQLite-specific configuration
#[derive(Debug, Clone)]
pub struct SQLiteConfig {
    /// Database file path (or ":memory:" for in-memory)
    pub path: String,
    /// Whether this is a temporary/in-memory database
    pub temporary: bool,
    /// Enable WAL mode for better concurrency
    pub enable_wal: bool,
    /// SQLite page size in bytes
    pub page_size: u32,
    /// SQLite cache size in pages
    pub cache_size: i32,
}

impl Default for SQLiteConfig {
    fn default() -> Self {
        Self {
            path: ":memory:".to_string(),
            temporary: true,
            enable_wal: false, // Disabled for in-memory databases
            page_size: 4096,   // 4KB pages
            cache_size: 2000,  // ~8MB cache
        }
    }
}

/// Connection pool for managing SQLite connections
struct ConnectionPool {
    /// The libSQL database instance
    database: Database,
    /// Available connections
    available: Vec<Connection>,
    /// Maximum pool size
    max_size: usize,
    /// Configuration
    config: SQLiteConfig,
}

#[allow(dead_code)]
impl ConnectionPool {
    /// Create a new connection pool
    async fn new(config: SQLiteConfig) -> Result<Self, DatabaseError> {
        let database = if config.path == ":memory:" {
            Builder::new_local(":memory:")
        } else {
            Builder::new_local(&config.path)
        }
        .build()
        .await
        .map_err(|e| DatabaseError::Configuration {
            message: format!(
                "Failed to create Turso/SQLite database at '{}': {}. \
                 Error details: {:?}. Check database path, permissions, and disk space.",
                config.path, e, e
            ),
        })?;

        // Initialize the database with our schema
        let conn = database
            .connect()
            .map_err(|e| DatabaseError::Configuration {
                message: format!(
                    "Failed to get initial connection to Turso/SQLite database at '{}': {}. \
                     Error details: {:?}. This may indicate database file corruption or access issues.",
                    config.path, e, e
                ),
            })?;

        Self::run_migrations(&conn, &config).await?;

        // Pre-populate with some connections
        let initial_size = if config.temporary { 1 } else { 2 };
        let mut available = Vec::with_capacity(initial_size);
        for _ in 0..initial_size {
            if let Ok(conn) = database.connect() {
                Self::configure_connection(&conn, &config).await?;
                available.push(conn);
            }
        }

        Ok(Self {
            database,
            available,
            max_size: 8,
            config,
        })
    }

    /// Run database migrations to ensure schema is up to date
    async fn run_migrations(conn: &Connection, config: &SQLiteConfig) -> Result<(), DatabaseError> {
        // Configure SQLite settings first
        if config.enable_wal && config.path != ":memory:" {
            // Try to enable WAL mode, but don't fail if it's not supported
            if conn.execute("PRAGMA journal_mode = WAL", ()).await.is_err() {
                warn!("WAL mode not supported, continuing with default journal mode");
            }
        }

        // Note: page_size and cache_size pragmas are not supported in Turso
        // The database handles these settings automatically

        // Create and run migration system
        let migrations = all_migrations();
        let runner =
            MigrationRunner::new(migrations).map_err(|e| DatabaseError::Configuration {
                message: format!("Failed to create migration runner: {e}"),
            })?;

        // Check if migrations are needed
        let needs_migration =
            runner
                .needs_migration(conn)
                .await
                .map_err(|e| DatabaseError::Configuration {
                    message: format!("Failed to check if migrations are needed: {e}"),
                })?;

        if needs_migration {
            info!("Running database migrations...");
            let applied_count =
                runner
                    .migrate_to(conn, None)
                    .await
                    .map_err(|e| DatabaseError::Configuration {
                        message: format!("Failed to run migrations: {e}"),
                    })?;
            info!("Applied {} database migrations successfully", applied_count);
        } else {
            info!("Database schema is up to date, no migrations needed");
        }

        // Performance indexes and views are now included in migrations
        // Only create the per-instance indexes that need unique suffixes (for tree tables)
        // These will be created when trees are opened

        Ok(())
    }

    /// Legacy method kept for backward compatibility
    /// Now delegates to the migration system
    #[allow(dead_code)]
    async fn initialize_schema(
        conn: &Connection,
        config: &SQLiteConfig,
    ) -> Result<(), DatabaseError> {
        Self::run_migrations(conn, config).await
    }

    /// Configure a connection with optimal settings
    async fn configure_connection(
        _conn: &Connection,
        _config: &SQLiteConfig,
    ) -> Result<(), DatabaseError> {
        // Most SQLite pragmas are not supported in Turso
        // The database handles optimization automatically
        Ok(())
    }

    /// Create schema version control table
    async fn create_schema_version_table(conn: &Connection) -> Result<(), DatabaseError> {
        conn.execute(
            r#"
            CREATE TABLE IF NOT EXISTS schema_version (
                version INTEGER PRIMARY KEY,
                applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                description TEXT
            )
            "#,
            (),
        )
        .await
        .map_err(|e| DatabaseError::Configuration {
            message: format!(
                "Failed to create schema_version table in Turso/SQLite database: {e}. \
                 Error details: {e:?}. This may indicate schema conflicts or insufficient permissions."
            ),
        })?;
        Ok(())
    }

    /// Create legacy tables for backward compatibility (currently empty - all legacy tables removed)
    async fn create_legacy_tables(_conn: &Connection) -> Result<(), DatabaseError> {
        // All unused cache tables (kv_store, tree_metadata) have been removed
        // Only core PRD tables (symbol_state, edges, etc.) are now used for caching
        Ok(())
    }

    /// Create core PRD tables (workspaces, files, file_versions)
    async fn create_core_tables(conn: &Connection) -> Result<(), DatabaseError> {
        // 1. Projects/Workspaces table
        conn.execute(
            r#"
            CREATE TABLE IF NOT EXISTS project (
                project_id TEXT PRIMARY KEY,
                root_path TEXT NOT NULL UNIQUE,
                name TEXT NOT NULL,
                description TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                metadata TEXT
            )
            "#,
            (),
        )
        .await
        .map_err(|e| DatabaseError::Configuration {
            message: format!("Failed to create project table: {e}"),
        })?;

        // 2. Workspaces table (project workspaces with branch support)
        conn.execute(
            r#"
            CREATE TABLE IF NOT EXISTS workspace (
                workspace_id TEXT PRIMARY KEY,
                project_id TEXT NOT NULL,
                name TEXT NOT NULL,
                path TEXT NOT NULL,
                current_branch TEXT,
                head_commit TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                metadata TEXT,
                FOREIGN KEY (project_id) REFERENCES project(project_id) ON DELETE CASCADE
            )
            "#,
            (),
        )
        .await
        .map_err(|e| DatabaseError::Configuration {
            message: format!("Failed to create workspace table: {e}"),
        })?;

        // 3. Workspace file mapping (current workspace file mappings)
        conn.execute(
            r#"
            CREATE TABLE IF NOT EXISTS workspace_file (
                workspace_file_id TEXT PRIMARY KEY,
                workspace_id TEXT NOT NULL,
                file_id TEXT NOT NULL,
                is_active BOOLEAN DEFAULT TRUE,
                added_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (workspace_id) REFERENCES workspace(workspace_id) ON DELETE CASCADE
            )
            "#,
            (),
        )
        .await
        .map_err(|e| DatabaseError::Configuration {
            message: format!("Failed to create workspace_file table: {e}"),
        })?;

        // 4. Workspace language configuration
        conn.execute(
            r#"
            CREATE TABLE IF NOT EXISTS workspace_language_config (
                config_id TEXT PRIMARY KEY,
                workspace_id TEXT NOT NULL,
                language TEXT NOT NULL,
                analyzer_type TEXT NOT NULL,
                settings TEXT,
                is_enabled BOOLEAN DEFAULT TRUE,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (workspace_id) REFERENCES workspace(workspace_id) ON DELETE CASCADE
            )
            "#,
            (),
        )
        .await
        .map_err(|e| DatabaseError::Configuration {
            message: format!("Failed to create workspace_language_config table: {e}"),
        })?;

        // 5. Workspace file analysis tracking
        conn.execute(
            r#"
            CREATE TABLE IF NOT EXISTS workspace_file_analysis (
                analysis_id TEXT PRIMARY KEY,
                workspace_id TEXT NOT NULL,
                file_id TEXT NOT NULL,
                analyzer_type TEXT NOT NULL,
                analysis_version TEXT,
                last_analyzed TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                status TEXT DEFAULT 'pending',
                FOREIGN KEY (workspace_id) REFERENCES workspace(workspace_id) ON DELETE CASCADE
            )
            "#,
            (),
        )
        .await
        .map_err(|e| DatabaseError::Configuration {
            message: format!("Failed to create workspace_file_analysis table: {e}"),
        })?;

        // 6. File registry with project association
        conn.execute(
            r#"
            CREATE TABLE IF NOT EXISTS file (
                file_id TEXT PRIMARY KEY,
                project_id TEXT NOT NULL,
                relative_path TEXT NOT NULL,
                absolute_path TEXT NOT NULL,
                language TEXT,
                size_bytes INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (project_id) REFERENCES project(project_id) ON DELETE CASCADE
            )
            "#,
            (),
        )
        .await
        .map_err(|e| DatabaseError::Configuration {
            message: format!("Failed to create file table: {e}"),
        })?;

        // 7. File versions with content-addressed storage
        conn.execute(
            r#"
            CREATE TABLE IF NOT EXISTS file_version (
                version_id TEXT PRIMARY KEY,
                file_id TEXT NOT NULL,
                content_hash TEXT NOT NULL,
                git_commit_hash TEXT,
                size_bytes INTEGER,
                line_count INTEGER,
                last_modified TIMESTAMP,
                indexed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (file_id) REFERENCES file(file_id) ON DELETE CASCADE
            )
            "#,
            (),
        )
        .await
        .map_err(|e| DatabaseError::Configuration {
            message: format!("Failed to create file_version table: {e}"),
        })?;

        // 8. Analysis run tracking
        conn.execute(
            r#"
            CREATE TABLE IF NOT EXISTS analysis_run (
                run_id TEXT PRIMARY KEY,
                workspace_id TEXT NOT NULL,
                analyzer_type TEXT NOT NULL,
                analyzer_version TEXT,
                configuration TEXT,
                started_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                completed_at TIMESTAMP,
                status TEXT DEFAULT 'running',
                files_processed INTEGER DEFAULT 0,
                symbols_found INTEGER DEFAULT 0,
                errors TEXT,
                FOREIGN KEY (workspace_id) REFERENCES workspace(workspace_id) ON DELETE CASCADE
            )
            "#,
            (),
        )
        .await
        .map_err(|e| DatabaseError::Configuration {
            message: format!("Failed to create analysis_run table: {e}"),
        })?;

        // 9. File analysis status and results
        conn.execute(
            r#"
            CREATE TABLE IF NOT EXISTS file_analysis (
                analysis_id TEXT PRIMARY KEY,
                run_id TEXT NOT NULL,
                file_id TEXT NOT NULL,
                version_id TEXT NOT NULL,
                status TEXT DEFAULT 'pending',
                started_at TIMESTAMP,
                completed_at TIMESTAMP,
                symbols_found INTEGER DEFAULT 0,
                references_found INTEGER DEFAULT 0,
                errors TEXT,
                FOREIGN KEY (run_id) REFERENCES analysis_run(run_id) ON DELETE CASCADE,
                FOREIGN KEY (file_id) REFERENCES file(file_id) ON DELETE CASCADE,
                FOREIGN KEY (version_id) REFERENCES file_version(version_id) ON DELETE CASCADE
            )
            "#,
            (),
        )
        .await
        .map_err(|e| DatabaseError::Configuration {
            message: format!("Failed to create file_analysis table: {e}"),
        })?;

        Ok(())
    }

    /// Create relationship tables (symbols, hierarchy, references, calls)
    async fn create_relationship_tables(conn: &Connection) -> Result<(), DatabaseError> {
        // 10. Symbol registry
        conn.execute(
            r#"
            CREATE TABLE IF NOT EXISTS symbol (
                symbol_id TEXT PRIMARY KEY,
                project_id TEXT NOT NULL,
                file_id TEXT NOT NULL,
                name TEXT NOT NULL,
                qualified_name TEXT,
                symbol_type TEXT NOT NULL,
                language TEXT NOT NULL,
                start_line INTEGER NOT NULL,
                start_column INTEGER NOT NULL,
                end_line INTEGER NOT NULL,
                end_column INTEGER NOT NULL,
                signature TEXT,
                documentation TEXT,
                visibility TEXT,
                modifiers TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (project_id) REFERENCES project(project_id) ON DELETE CASCADE,
                FOREIGN KEY (file_id) REFERENCES file(file_id) ON DELETE CASCADE
            )
            "#,
            (),
        )
        .await
        .map_err(|e| DatabaseError::Configuration {
            message: format!("Failed to create symbol table: {e}"),
        })?;

        // 11. Symbol definitions with versioning
        conn.execute(
            r#"
            CREATE TABLE IF NOT EXISTS symbol_state (
                state_id TEXT PRIMARY KEY,
                symbol_id TEXT NOT NULL,
                version_id TEXT NOT NULL,
                git_commit_hash TEXT,
                definition_data TEXT NOT NULL,
                indexed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                confidence REAL DEFAULT 1.0,
                FOREIGN KEY (symbol_id) REFERENCES symbol(symbol_id) ON DELETE CASCADE,
                FOREIGN KEY (version_id) REFERENCES file_version(version_id) ON DELETE CASCADE
            )
            "#,
            (),
        )
        .await
        .map_err(|e| DatabaseError::Configuration {
            message: format!("Failed to create symbol_state table: {e}"),
        })?;

        // 12. Relationships between symbols
        conn.execute(
            r#"
            CREATE TABLE IF NOT EXISTS edge (
                edge_id TEXT PRIMARY KEY,
                project_id TEXT NOT NULL,
                source_symbol_id TEXT NOT NULL,
                target_symbol_id TEXT NOT NULL,
                edge_type TEXT NOT NULL,
                file_id TEXT NOT NULL,
                version_id TEXT NOT NULL,
                git_commit_hash TEXT,
                source_location TEXT,
                target_location TEXT,
                confidence REAL DEFAULT 1.0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (project_id) REFERENCES project(project_id) ON DELETE CASCADE,
                FOREIGN KEY (source_symbol_id) REFERENCES symbol(symbol_id) ON DELETE CASCADE,
                FOREIGN KEY (target_symbol_id) REFERENCES symbol(symbol_id) ON DELETE CASCADE,
                FOREIGN KEY (file_id) REFERENCES file(file_id) ON DELETE CASCADE,
                FOREIGN KEY (version_id) REFERENCES file_version(version_id) ON DELETE CASCADE
            )
            "#,
            (),
        )
        .await
        .map_err(|e| DatabaseError::Configuration {
            message: format!("Failed to create edge table: {e}"),
        })?;

        // 13. File dependency relationships
        conn.execute(
            r#"
            CREATE TABLE IF NOT EXISTS file_dependency (
                dependency_id TEXT PRIMARY KEY,
                project_id TEXT NOT NULL,
                source_file_id TEXT NOT NULL,
                target_file_id TEXT NOT NULL,
                dependency_type TEXT NOT NULL,
                import_statement TEXT,
                version_id TEXT NOT NULL,
                git_commit_hash TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (project_id) REFERENCES project(project_id) ON DELETE CASCADE,
                FOREIGN KEY (source_file_id) REFERENCES file(file_id) ON DELETE CASCADE,
                FOREIGN KEY (target_file_id) REFERENCES file(file_id) ON DELETE CASCADE,
                FOREIGN KEY (version_id) REFERENCES file_version(version_id) ON DELETE CASCADE
            )
            "#,
            (),
        )
        .await
        .map_err(|e| DatabaseError::Configuration {
            message: format!("Failed to create file_dependency table: {e}"),
        })?;

        // 14. Symbol change tracking
        conn.execute(
            r#"
            CREATE TABLE IF NOT EXISTS symbol_change (
                change_id TEXT PRIMARY KEY,
                symbol_id TEXT NOT NULL,
                previous_state_id TEXT,
                current_state_id TEXT NOT NULL,
                change_type TEXT NOT NULL,
                git_commit_hash TEXT,
                changed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                change_description TEXT,
                FOREIGN KEY (symbol_id) REFERENCES symbol(symbol_id) ON DELETE CASCADE,
                FOREIGN KEY (previous_state_id) REFERENCES symbol_state(state_id) ON DELETE SET NULL,
                FOREIGN KEY (current_state_id) REFERENCES symbol_state(state_id) ON DELETE CASCADE
            )
            "#,
            (),
        ).await.map_err(|e| DatabaseError::Configuration {
            message: format!("Failed to create symbol_change table: {e}"),
        })?;

        Ok(())
    }

    /// Create cache and analytics tables
    async fn create_cache_tables(conn: &Connection) -> Result<(), DatabaseError> {
        // 15. Analysis queue management
        conn.execute(
            r#"
            CREATE TABLE IF NOT EXISTS indexer_queue (
                queue_id TEXT PRIMARY KEY,
                workspace_id TEXT NOT NULL,
                file_id TEXT NOT NULL,
                priority INTEGER DEFAULT 0,
                operation_type TEXT NOT NULL,
                status TEXT DEFAULT 'pending',
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                started_at TIMESTAMP,
                completed_at TIMESTAMP,
                retry_count INTEGER DEFAULT 0,
                error_message TEXT,
                FOREIGN KEY (workspace_id) REFERENCES workspace(workspace_id) ON DELETE CASCADE,
                FOREIGN KEY (file_id) REFERENCES file(file_id) ON DELETE CASCADE
            )
            "#,
            (),
        )
        .await
        .map_err(|e| DatabaseError::Configuration {
            message: format!("Failed to create indexer_queue table: {e}"),
        })?;

        // 16. Progress tracking
        conn.execute(
            r#"
            CREATE TABLE IF NOT EXISTS indexer_checkpoint (
                checkpoint_id TEXT PRIMARY KEY,
                workspace_id TEXT NOT NULL,
                operation_type TEXT NOT NULL,
                last_processed_file TEXT,
                files_processed INTEGER DEFAULT 0,
                total_files INTEGER DEFAULT 0,
                checkpoint_data TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (workspace_id) REFERENCES workspace(workspace_id) ON DELETE CASCADE
            )
            "#,
            (),
        )
        .await
        .map_err(|e| DatabaseError::Configuration {
            message: format!("Failed to create indexer_checkpoint table: {e}"),
        })?;

        Ok(())
    }

    /// Create all performance indexes from PRD specification
    async fn create_performance_indexes(
        conn: &Connection,
        config: &SQLiteConfig,
    ) -> Result<(), DatabaseError> {
        // Generate a unique suffix for this database instance to avoid index conflicts
        let mut hasher = std::collections::hash_map::DefaultHasher::new();
        config.path.hash(&mut hasher);
        std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap_or_default()
            .as_nanos()
            .hash(&mut hasher);
        let db_suffix = format!("{:x}", hasher.finish())[..8].to_string();
        let indexes = vec![
            // Project indexes
            format!("CREATE INDEX IF NOT EXISTS idx_project_root_path_{db_suffix} ON project(root_path)"),
            // Workspace indexes
            format!("CREATE INDEX IF NOT EXISTS idx_workspace_project_{db_suffix} ON workspace(project_id)"),
            format!("CREATE INDEX IF NOT EXISTS idx_workspace_path_{db_suffix} ON workspace(path)"),
            format!("CREATE INDEX IF NOT EXISTS idx_workspace_branch_{db_suffix} ON workspace(current_branch)"),
            // File indexes
            format!("CREATE INDEX IF NOT EXISTS idx_file_project_{db_suffix} ON file(project_id)"),
            format!("CREATE INDEX IF NOT EXISTS idx_file_language_{db_suffix} ON file(language)"),
            format!("CREATE INDEX IF NOT EXISTS idx_file_relative_path_{db_suffix} ON file(project_id, relative_path)"),
            // File version indexes
            format!("CREATE INDEX IF NOT EXISTS idx_file_version_file_time_{db_suffix} ON file_version(file_id, indexed_at DESC)"),
            format!("CREATE INDEX IF NOT EXISTS idx_file_version_commit_{db_suffix} ON file_version(git_commit_hash)"),
            format!("CREATE INDEX IF NOT EXISTS idx_file_version_content_hash_{db_suffix} ON file_version(content_hash)"),
            // Symbol indexes
            format!("CREATE INDEX IF NOT EXISTS idx_symbol_project_{db_suffix} ON symbol(project_id)"),
            format!("CREATE INDEX IF NOT EXISTS idx_symbol_file_{db_suffix} ON symbol(file_id)"),
            format!("CREATE INDEX IF NOT EXISTS idx_symbol_name_{db_suffix} ON symbol(project_id, name)"),
            format!("CREATE INDEX IF NOT EXISTS idx_symbol_qualified_name_{db_suffix} ON symbol(project_id, qualified_name)"),
            format!("CREATE INDEX IF NOT EXISTS idx_symbol_type_{db_suffix} ON symbol(project_id, symbol_type)"),
            format!("CREATE INDEX IF NOT EXISTS idx_symbol_language_{db_suffix} ON symbol(language)"),
            // Symbol state indexes
            format!("CREATE INDEX IF NOT EXISTS idx_symbol_state_symbol_{db_suffix} ON symbol_state(symbol_id)"),
            format!("CREATE INDEX IF NOT EXISTS idx_symbol_state_version_{db_suffix} ON symbol_state(version_id)"),
            format!("CREATE INDEX IF NOT EXISTS idx_symbol_state_commit_{db_suffix} ON symbol_state(git_commit_hash)"),
            format!("CREATE INDEX IF NOT EXISTS idx_symbol_state_time_{db_suffix} ON symbol_state(symbol_id, indexed_at DESC)"),
            // Edge indexes
            format!("CREATE INDEX IF NOT EXISTS idx_edge_source_{db_suffix} ON edge(source_symbol_id)"),
            format!("CREATE INDEX IF NOT EXISTS idx_edge_target_{db_suffix} ON edge(target_symbol_id)"),
            format!("CREATE INDEX IF NOT EXISTS idx_edge_type_{db_suffix} ON edge(project_id, edge_type)"),
            format!("CREATE INDEX IF NOT EXISTS idx_edge_file_{db_suffix} ON edge(file_id, version_id)"),
            format!("CREATE INDEX IF NOT EXISTS idx_edge_commit_{db_suffix} ON edge(git_commit_hash)"),
            // File dependency indexes
            format!("CREATE INDEX IF NOT EXISTS idx_file_dep_source_{db_suffix} ON file_dependency(source_file_id)"),
            format!("CREATE INDEX IF NOT EXISTS idx_file_dep_target_{db_suffix} ON file_dependency(target_file_id)"),
            format!("CREATE INDEX IF NOT EXISTS idx_file_dep_type_{db_suffix} ON file_dependency(project_id, dependency_type)"),
            format!("CREATE INDEX IF NOT EXISTS idx_file_dep_commit_{db_suffix} ON file_dependency(git_commit_hash)"),
            // Analysis indexes
            format!("CREATE INDEX IF NOT EXISTS idx_analysis_run_workspace_{db_suffix} ON analysis_run(workspace_id, started_at DESC)"),
            format!("CREATE INDEX IF NOT EXISTS idx_file_analysis_run_{db_suffix} ON file_analysis(run_id)"),
            format!("CREATE INDEX IF NOT EXISTS idx_file_analysis_file_{db_suffix} ON file_analysis(file_id, version_id)"),
            // Workspace indexes
            format!("CREATE INDEX IF NOT EXISTS idx_workspace_file_workspace_{db_suffix} ON workspace_file(workspace_id)"),
            format!("CREATE INDEX IF NOT EXISTS idx_workspace_file_active_{db_suffix} ON workspace_file(workspace_id, is_active)"),
            format!("CREATE INDEX IF NOT EXISTS idx_workspace_lang_config_{db_suffix} ON workspace_language_config(workspace_id, language)"),
            format!("CREATE INDEX IF NOT EXISTS idx_workspace_analysis_{db_suffix} ON workspace_file_analysis(workspace_id, file_id)"),
            // Queue indexes
            format!("CREATE INDEX IF NOT EXISTS idx_indexer_queue_workspace_{db_suffix} ON indexer_queue(workspace_id, status, priority DESC)"),
            format!("CREATE INDEX IF NOT EXISTS idx_indexer_queue_status_{db_suffix} ON indexer_queue(status, created_at)"),
            format!("CREATE INDEX IF NOT EXISTS idx_indexer_checkpoint_workspace_{db_suffix} ON indexer_checkpoint(workspace_id, operation_type)"),
            // Change tracking indexes
            format!("CREATE INDEX IF NOT EXISTS idx_symbol_change_symbol_{db_suffix} ON symbol_change(symbol_id, changed_at DESC)"),
            format!("CREATE INDEX IF NOT EXISTS idx_symbol_change_commit_{db_suffix} ON symbol_change(git_commit_hash)"),
        ];

        for sql in &indexes {
            conn.execute(sql, ())
                .await
                .map_err(|e| DatabaseError::Configuration {
                    message: format!("Failed to create index: {sql}. Error: {e}"),
                })?;
        }

        Ok(())
    }

    /// Create utility views from PRD specification
    async fn create_utility_views(
        conn: &Connection,
        config: &SQLiteConfig,
    ) -> Result<(), DatabaseError> {
        // Generate a unique suffix for this database instance to avoid view conflicts
        let mut hasher = std::collections::hash_map::DefaultHasher::new();
        config.path.hash(&mut hasher);
        std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap_or_default()
            .as_nanos()
            .hash(&mut hasher);
        let db_suffix = format!("{:x}", hasher.finish())[..8].to_string();
        // Current symbols view (handles git + timestamp logic)
        let current_symbols_sql = format!(
            r#"
            CREATE VIEW IF NOT EXISTS current_symbols_{db_suffix} AS
            WITH latest_modified AS (
                SELECT DISTINCT 
                    symbol_id,
                    project_id,
                    MAX(ss.indexed_at) as latest_indexed_at
                FROM symbol_state ss
                WHERE ss.git_commit_hash IS NULL
                GROUP BY symbol_id, project_id
            )
            SELECT DISTINCT 
                s.*,
                ss.definition_data,
                ss.confidence,
                ss.indexed_at
            FROM symbol s
            JOIN symbol_state ss ON s.symbol_id = ss.symbol_id
            LEFT JOIN latest_modified lm ON s.symbol_id = lm.symbol_id AND s.project_id = lm.project_id
            WHERE 
                (ss.git_commit_hash IS NULL AND ss.indexed_at = lm.latest_indexed_at)
                OR 
                (ss.git_commit_hash IS NOT NULL)
            "#
        );

        conn.execute(&current_symbols_sql, ())
            .await
            .map_err(|e| DatabaseError::Configuration {
                message: format!("Failed to create current_symbols view: {e}"),
            })?;

        // Symbols with file info view
        let symbols_with_files_sql = format!(
            r#"
            CREATE VIEW IF NOT EXISTS symbols_with_files_{db_suffix} AS
            SELECT 
                s.*,
                f.relative_path,
                f.absolute_path,
                f.language as file_language,
                p.name as project_name,
                p.root_path
            FROM symbol s
            JOIN file f ON s.file_id = f.file_id
            JOIN project p ON s.project_id = p.project_id
            "#
        );

        conn.execute(&symbols_with_files_sql, ())
            .await
            .map_err(|e| DatabaseError::Configuration {
                message: format!("Failed to create symbols_with_files view: {e}"),
            })?;

        // Edge relationships with symbol names view
        let edges_named_sql = format!(
            r#"
            CREATE VIEW IF NOT EXISTS edges_named_{db_suffix} AS
            SELECT 
                e.*,
                source.name as source_name,
                source.qualified_name as source_qualified,
                target.name as target_name,
                target.qualified_name as target_qualified,
                f.relative_path
            FROM edge e
            JOIN symbol source ON e.source_symbol_id = source.symbol_id
            JOIN symbol target ON e.target_symbol_id = target.symbol_id
            JOIN file f ON e.file_id = f.file_id
            "#
        );

        conn.execute(&edges_named_sql, ())
            .await
            .map_err(|e| DatabaseError::Configuration {
                message: format!("Failed to create edges_named view: {e}"),
            })?;

        // File dependencies with names view
        let file_dependencies_named_sql = format!(
            r#"
            CREATE VIEW IF NOT EXISTS file_dependencies_named_{db_suffix} AS
            SELECT 
                fd.*,
                source.relative_path as source_path,
                target.relative_path as target_path,
                source.language as source_language,
                target.language as target_language
            FROM file_dependency fd
            JOIN file source ON fd.source_file_id = source.file_id
            JOIN file target ON fd.target_file_id = target.file_id
            "#
        );

        conn.execute(&file_dependencies_named_sql, ())
            .await
            .map_err(|e| DatabaseError::Configuration {
                message: format!("Failed to create file_dependencies_named view: {e}"),
            })?;

        Ok(())
    }

    /// Initialize or validate schema version
    async fn initialize_schema_version(conn: &Connection) -> Result<(), DatabaseError> {
        // Check if schema version exists
        let mut rows = conn
            .query(
                "SELECT version FROM schema_version ORDER BY version DESC LIMIT 1",
                (),
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to check schema version: {e}"),
            })?;

        if let Some(row) = rows
            .next()
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to read schema version: {e}"),
            })?
        {
            // Schema version exists, validate it
            if let Ok(turso::Value::Integer(version)) = row.get_value(0) {
                if version != 1 {
                    return Err(DatabaseError::Configuration {
                        message: format!(
                            "Unsupported schema version: {version}. Expected version 1."
                        ),
                    });
                }
            }
        } else {
            // Initialize schema version
            conn.execute(
                "INSERT INTO schema_version (version, description) VALUES (1, 'Initial PRD schema with core tables, indexes, and views')",
                (),
            )
            .await
            .map_err(|e| DatabaseError::Configuration {
                message: format!("Failed to initialize schema version: {e}"),
            })?;
        }

        Ok(())
    }

    /// Get a connection from the pool
    async fn get_connection(&mut self) -> Result<Connection, DatabaseError> {
        if let Some(conn) = self.available.pop() {
            Ok(conn)
        } else {
            // Create a new connection if we haven't hit the max
            let conn = self
                .database
                .connect()
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to create new connection: {e}"),
                })?;
            Self::configure_connection(&conn, &self.config).await?;
            Ok(conn)
        }
    }

    /// Return a connection to the pool
    fn return_connection(&mut self, conn: Connection) {
        if self.available.len() < self.max_size {
            self.available.push(conn);
        }
        // If pool is full, just drop the connection
    }
}

/// SQLite-based implementation of DatabaseTree
pub struct SQLiteTree {
    /// Tree name (used as table suffix)
    name: String,
    /// Connection pool reference
    pool: Arc<Mutex<ConnectionPool>>,
}

#[async_trait]
impl DatabaseTree for SQLiteTree {
    async fn get(&self, key: &[u8]) -> Result<Option<Vec<u8>>, DatabaseError> {
        let key_str = String::from_utf8_lossy(key);
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let table_name = format!("tree_{}", sanitize_table_name(&self.name));
        let sql = format!("SELECT value FROM {table_name} WHERE key = ?");

        let mut rows = conn
            .query(&sql, [turso::Value::Text(key_str.to_string())])
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to get key from tree '{}': {}", self.name, e),
            })?;

        let value = if let Some(row) =
            rows.next()
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to iterate rows in tree '{}': {}", self.name, e),
                })? {
            match row.get_value(0) {
                Ok(turso::Value::Blob(blob)) => Some(blob),
                _ => None,
            }
        } else {
            None
        };

        pool.return_connection(conn);
        Ok(value)
    }

    async fn set(&self, key: &[u8], value: &[u8]) -> Result<(), DatabaseError> {
        let key_str = String::from_utf8_lossy(key);
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let table_name = format!("tree_{}", sanitize_table_name(&self.name));
        // Use UPDATE/INSERT pattern since Turso doesn't support OR REPLACE
        let update_sql = format!(
            "UPDATE {table_name} SET value = ?, updated_at = strftime('%s','now') WHERE key = ?"
        );
        let insert_sql = format!(
            "INSERT INTO {table_name} (key, value, created_at, updated_at) VALUES (?, ?, strftime('%s','now'), strftime('%s','now'))"
        );

        // Try update first
        let rows_updated = conn
            .execute(
                &update_sql,
                [
                    turso::Value::Blob(value.to_vec()),
                    turso::Value::Text(key_str.to_string()),
                ],
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to update key in tree '{}': {}", self.name, e),
            })?;

        // If no rows were updated, insert new record
        if rows_updated == 0 {
            conn.execute(
                &insert_sql,
                [
                    turso::Value::Text(key_str.to_string()),
                    turso::Value::Blob(value.to_vec()),
                ],
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to insert key in tree '{}': {}", self.name, e),
            })?;
        }

        pool.return_connection(conn);
        Ok(())
    }

    async fn remove(&self, key: &[u8]) -> Result<bool, DatabaseError> {
        let key_str = String::from_utf8_lossy(key);
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let table_name = format!("tree_{}", sanitize_table_name(&self.name));
        let sql = format!("DELETE FROM {table_name} WHERE key = ?");

        let rows_affected = conn
            .execute(&sql, [turso::Value::Text(key_str.to_string())])
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to remove key from tree '{}': {}", self.name, e),
            })?;

        pool.return_connection(conn);
        Ok(rows_affected > 0)
    }

    async fn scan_prefix(&self, prefix: &[u8]) -> Result<Vec<(Vec<u8>, Vec<u8>)>, DatabaseError> {
        let prefix_str = String::from_utf8_lossy(prefix);
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let table_name = format!("tree_{}", sanitize_table_name(&self.name));
        let sql = if prefix.is_empty() {
            format!("SELECT key, value FROM {table_name} ORDER BY key")
        } else {
            format!("SELECT key, value FROM {table_name} WHERE key GLOB ? || '*' ORDER BY key")
        };

        let params = if prefix.is_empty() {
            Vec::new()
        } else {
            vec![turso::Value::Text(prefix_str.to_string())]
        };

        let mut rows =
            conn.query(&sql, params)
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to scan prefix in tree '{}': {}", self.name, e),
                })?;

        let mut results = Vec::new();
        while let Some(row) = rows
            .next()
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to iterate rows in tree '{}': {}", self.name, e),
            })?
        {
            if let (Ok(turso::Value::Text(key)), Ok(turso::Value::Blob(value))) =
                (row.get_value(0), row.get_value(1))
            {
                results.push((key.as_bytes().to_vec(), value));
            }
            // Skip malformed rows
        }

        pool.return_connection(conn);
        Ok(results)
    }

    async fn clear(&self) -> Result<(), DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let table_name = format!("tree_{}", sanitize_table_name(&self.name));
        let sql = format!("DELETE FROM {table_name}");

        conn.execute(&sql, ())
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to clear tree '{}': {}", self.name, e),
            })?;

        pool.return_connection(conn);
        Ok(())
    }

    async fn len(&self) -> Result<u64, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let table_name = format!("tree_{}", sanitize_table_name(&self.name));
        let sql = format!("SELECT COUNT(*) FROM {table_name}");

        let mut rows = conn
            .query(&sql, ())
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to get length of tree '{}': {}", self.name, e),
            })?;

        let count = if let Some(row) =
            rows.next()
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to iterate rows in tree '{}': {}", self.name, e),
                })? {
            match row.get_value(0) {
                Ok(turso::Value::Integer(n)) => n as u64,
                _ => 0,
            }
        } else {
            0
        };

        pool.return_connection(conn);
        Ok(count)
    }
}

/// SQLite database backend implementation
pub struct SQLiteBackend {
    /// Connection pool
    pool: Arc<Mutex<ConnectionPool>>,
    /// SQLite-specific configuration
    sqlite_config: SQLiteConfig,
    /// Cache of opened trees
    trees: RwLock<HashMap<String, Arc<SQLiteTree>>>,
}

impl SQLiteBackend {
    /// Create a new SQLiteBackend with custom SQLite configuration
    pub async fn with_sqlite_config(
        _config: DatabaseConfig,
        sqlite_config: SQLiteConfig,
    ) -> Result<Self, DatabaseError> {
        let pool = ConnectionPool::new(sqlite_config.clone()).await?;

        let backend = Self {
            pool: Arc::new(Mutex::new(pool)),
            sqlite_config: sqlite_config.clone(),
            trees: RwLock::new(HashMap::new()),
        };

        if sqlite_config.temporary {
            info!("Initialized temporary SQLite database (in-memory)");
        } else {
            info!(
                "Initialized persistent SQLite database at: {}",
                sqlite_config.path
            );
        }

        Ok(backend)
    }

    /// Create a new tree table if it doesn't exist
    async fn ensure_tree_table(&self, tree_name: &str) -> Result<(), DatabaseError> {
        let sanitized_name = sanitize_table_name(tree_name);
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let table_name = format!("tree_{sanitized_name}");
        let sql = format!(
            r#"
            CREATE TABLE IF NOT EXISTS {table_name} (
                key TEXT PRIMARY KEY,
                value BLOB NOT NULL,
                created_at INTEGER DEFAULT (strftime('%s','now')),
                updated_at INTEGER DEFAULT (strftime('%s','now'))
            )
            "#
        );

        conn.execute(&sql, ())
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to create tree table '{tree_name}': {e}"),
            })?;

        // Create index for the tree with unique suffix to avoid conflicts
        // Use a hash of the tree name and a random component to ensure uniqueness
        let mut hasher = std::collections::hash_map::DefaultHasher::new();
        tree_name.hash(&mut hasher);
        // Add current time to ensure uniqueness across test runs
        std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap_or_default()
            .as_nanos()
            .hash(&mut hasher);
        let unique_suffix = hasher.finish();

        let index_name = format!("idx_{sanitized_name}_{unique_suffix:x}_key");
        let index_sql = format!("CREATE INDEX IF NOT EXISTS {index_name} ON {table_name}(key)");

        conn.execute(&index_sql, ())
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to create index for tree '{tree_name}': {e}"),
            })?;

        // Update metadata - check if exists first, then insert if needed
        let mut rows = conn
            .query(
                "SELECT tree_name FROM tree_metadata WHERE tree_name = ?",
                [turso::Value::Text(tree_name.to_string())],
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to check tree metadata for '{tree_name}': {e}"),
            })?;

        if rows
            .next()
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to iterate metadata check for '{tree_name}': {e}"),
            })?
            .is_none()
        {
            // Tree doesn't exist in metadata, insert it
            conn.execute(
                "INSERT INTO tree_metadata (tree_name) VALUES (?)",
                [turso::Value::Text(tree_name.to_string())],
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to insert tree metadata for '{tree_name}': {e}"),
            })?;
        }

        pool.return_connection(conn);
        Ok(())
    }

    /// Get current database schema version
    pub async fn get_schema_version(&self) -> Result<u32, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let result = crate::database::migrations::get_current_version(&conn)
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to get schema version: {e}"),
            });

        pool.return_connection(conn);
        result
    }

    /// Run migrations manually up to target version
    pub async fn migrate_to(&self, target_version: Option<u32>) -> Result<u32, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let migrations = all_migrations();
        let runner =
            MigrationRunner::new(migrations).map_err(|e| DatabaseError::Configuration {
                message: format!("Failed to create migration runner: {e}"),
            })?;

        let result = runner.migrate_to(&conn, target_version).await.map_err(|e| {
            DatabaseError::OperationFailed {
                message: format!("Failed to run migrations: {e}"),
            }
        });

        pool.return_connection(conn);
        result
    }

    /// Rollback migrations to target version
    pub async fn rollback_to(&self, target_version: u32) -> Result<u32, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let migrations = all_migrations();
        let runner =
            MigrationRunner::new(migrations).map_err(|e| DatabaseError::Configuration {
                message: format!("Failed to create migration runner: {e}"),
            })?;

        let result = runner
            .rollback_to(&conn, target_version)
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to rollback migrations: {e}"),
            });

        pool.return_connection(conn);
        result
    }

    /// Check if migrations are needed
    pub async fn needs_migration(&self) -> Result<bool, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let migrations = all_migrations();
        let runner =
            MigrationRunner::new(migrations).map_err(|e| DatabaseError::Configuration {
                message: format!("Failed to create migration runner: {e}"),
            })?;

        let result =
            runner
                .needs_migration(&conn)
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to check migration status: {e}"),
                });

        pool.return_connection(conn);
        result
    }
}

#[async_trait]
impl DatabaseBackend for SQLiteBackend {
    type Tree = SQLiteTree;

    async fn new(config: DatabaseConfig) -> Result<Self, DatabaseError>
    where
        Self: Sized,
    {
        let sqlite_config = SQLiteConfig {
            path: if config.temporary {
                ":memory:".to_string()
            } else {
                config
                    .path
                    .as_ref()
                    .map(|p| p.to_string_lossy().to_string())
                    .unwrap_or_else(|| ":memory:".to_string())
            },
            temporary: config.temporary,
            enable_wal: !config.temporary, // Enable WAL for persistent databases
            page_size: 4096,
            cache_size: (config.cache_capacity / 4096).max(100) as i32, // Convert bytes to pages
        };

        Self::with_sqlite_config(config, sqlite_config).await
    }

    async fn get(&self, key: &[u8]) -> Result<Option<Vec<u8>>, DatabaseError> {
        let key_str = String::from_utf8_lossy(key);
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let mut rows = conn
            .query(
                "SELECT value FROM kv_store WHERE key = ?",
                [turso::Value::Text(key_str.to_string())],
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to get key from default store: {e}"),
            })?;

        let value = if let Some(row) =
            rows.next()
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to iterate rows in default store: {e}"),
                })? {
            match row.get_value(0) {
                Ok(turso::Value::Blob(blob)) => Some(blob),
                _ => None,
            }
        } else {
            None
        };

        pool.return_connection(conn);
        Ok(value)
    }

    async fn set(&self, key: &[u8], value: &[u8]) -> Result<(), DatabaseError> {
        let key_str = String::from_utf8_lossy(key);
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        // Try update first
        let rows_updated = conn
            .execute(
                "UPDATE kv_store SET value = ?, updated_at = strftime('%s','now') WHERE key = ?",
                [
                    turso::Value::Blob(value.to_vec()),
                    turso::Value::Text(key_str.to_string()),
                ],
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to update key in default store: {e}"),
            })?;

        // If no rows were updated, insert new record
        if rows_updated == 0 {
            conn.execute(
                "INSERT INTO kv_store (key, value, created_at, updated_at) VALUES (?, ?, strftime('%s','now'), strftime('%s','now'))",
                [
                    turso::Value::Text(key_str.to_string()),
                    turso::Value::Blob(value.to_vec()),
                ],
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to insert key in default store: {e}"),
            })?;
        }

        pool.return_connection(conn);
        Ok(())
    }

    async fn remove(&self, key: &[u8]) -> Result<bool, DatabaseError> {
        let key_str = String::from_utf8_lossy(key);
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let rows_affected = conn
            .execute(
                "DELETE FROM kv_store WHERE key = ?",
                [turso::Value::Text(key_str.to_string())],
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to remove key from default store: {e}"),
            })?;

        pool.return_connection(conn);
        Ok(rows_affected > 0)
    }

    async fn scan_prefix(&self, prefix: &[u8]) -> Result<Vec<(Vec<u8>, Vec<u8>)>, DatabaseError> {
        let prefix_str = String::from_utf8_lossy(prefix);
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let (sql, params) = if prefix.is_empty() {
            (
                "SELECT key, value FROM kv_store ORDER BY key".to_string(),
                Vec::new(),
            )
        } else {
            (
                "SELECT key, value FROM kv_store WHERE key GLOB ? || '*' ORDER BY key".to_string(),
                vec![turso::Value::Text(prefix_str.to_string())],
            )
        };

        let mut rows =
            conn.query(&sql, params)
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to scan prefix in default store: {e}"),
                })?;

        let mut results = Vec::new();
        while let Some(row) = rows
            .next()
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to iterate rows in default store: {e}"),
            })?
        {
            if let (Ok(turso::Value::Text(key)), Ok(turso::Value::Blob(value))) =
                (row.get_value(0), row.get_value(1))
            {
                results.push((key.as_bytes().to_vec(), value));
            }
            // Skip malformed rows
        }

        pool.return_connection(conn);
        Ok(results)
    }

    async fn open_tree(&self, name: &str) -> Result<Arc<Self::Tree>, DatabaseError> {
        // Check if tree already exists in cache
        {
            let trees = self.trees.read().await;
            if let Some(tree) = trees.get(name) {
                return Ok(Arc::clone(tree));
            }
        }

        // Ensure tree table exists
        self.ensure_tree_table(name).await?;

        // Create new tree instance
        let tree = Arc::new(SQLiteTree {
            name: name.to_string(),
            pool: Arc::clone(&self.pool),
        });

        // Cache the tree
        {
            let mut trees = self.trees.write().await;
            trees.insert(name.to_string(), Arc::clone(&tree));
        }

        Ok(tree)
    }

    async fn tree_names(&self) -> Result<Vec<String>, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let mut rows = conn
            .query("SELECT tree_name FROM tree_metadata ORDER BY tree_name", ())
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to get tree names: {e}"),
            })?;

        let mut names = Vec::new();
        while let Some(row) = rows
            .next()
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to iterate tree names: {e}"),
            })?
        {
            if let Ok(turso::Value::Text(name)) = row.get_value(0) {
                names.push(name);
            }
            // Skip malformed rows
        }

        pool.return_connection(conn);
        Ok(names)
    }

    async fn clear(&self) -> Result<(), DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        // Clear default key-value store
        conn.execute("DELETE FROM kv_store", ())
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to clear default store: {e}"),
            })?;

        // Clear all tree tables
        let tree_names = {
            let trees = self.trees.read().await;
            trees.keys().cloned().collect::<Vec<_>>()
        };

        for tree_name in &tree_names {
            let sanitized_name = sanitize_table_name(tree_name);
            let table_name = format!("tree_{sanitized_name}");
            let sql = format!("DELETE FROM {table_name}");
            conn.execute(&sql, ())
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to clear tree '{tree_name}': {e}"),
                })?;
        }

        pool.return_connection(conn);
        Ok(())
    }

    async fn flush(&self) -> Result<(), DatabaseError> {
        if !self.sqlite_config.temporary {
            // For Turso, flush is handled automatically by the underlying database
            // Most pragmas are not supported, so we'll just do a no-op for persistent databases
            // The database will be automatically flushed when connections are closed
        }
        Ok(())
    }

    async fn stats(&self) -> Result<DatabaseStats, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        // Count entries in default store
        let mut rows = conn
            .query("SELECT COUNT(*) FROM kv_store", ())
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to count default store entries: {e}"),
            })?;

        let default_count = if let Some(row) =
            rows.next()
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to iterate count result: {e}"),
                })? {
            match row.get_value(0) {
                Ok(turso::Value::Integer(n)) => n as u64,
                _ => 0,
            }
        } else {
            0
        };

        // Count entries in all trees
        let tree_names = {
            let trees = self.trees.read().await;
            trees.keys().cloned().collect::<Vec<_>>()
        };

        let mut total_entries = default_count;
        for tree_name in &tree_names {
            let sanitized_name = sanitize_table_name(tree_name);
            let table_name = format!("tree_{sanitized_name}");
            let sql = format!("SELECT COUNT(*) FROM {table_name}");

            let mut rows =
                conn.query(&sql, ())
                    .await
                    .map_err(|e| DatabaseError::OperationFailed {
                        message: format!("Failed to count entries in tree '{tree_name}': {e}"),
                    })?;

            if let Some(row) = rows
                .next()
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to iterate count result for tree '{tree_name}': {e}"),
                })?
            {
                if let Ok(turso::Value::Integer(n)) = row.get_value(0) {
                    total_entries += n as u64;
                }
            }
        }

        // Estimate total size (rough estimate)
        let estimated_avg_entry_size = 256; // bytes per entry
        let total_size_bytes = total_entries * estimated_avg_entry_size;

        let disk_size_bytes = if self.sqlite_config.temporary {
            0
        } else {
            self.size_on_disk().await?
        };

        pool.return_connection(conn);

        Ok(DatabaseStats {
            total_entries,
            total_size_bytes,
            disk_size_bytes,
            tree_count: tree_names.len(),
            is_temporary: self.sqlite_config.temporary,
        })
    }

    async fn size_on_disk(&self) -> Result<u64, DatabaseError> {
        if self.sqlite_config.temporary || self.sqlite_config.path == ":memory:" {
            return Ok(0);
        }

        let path = PathBuf::from(&self.sqlite_config.path);
        if path.exists() {
            std::fs::metadata(&path)
                .map(|metadata| metadata.len())
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to get database file size: {e}"),
                })
        } else {
            Ok(0)
        }
    }

    fn is_temporary(&self) -> bool {
        self.sqlite_config.temporary
    }

    // ===================
    // Workspace Management
    // ===================

    async fn create_workspace(
        &self,
        name: &str,
        project_id: i64,
        branch_hint: Option<&str>,
    ) -> Result<i64, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        // Generate a simple integer ID (timestamp-based)
        let workspace_id_int = self.generate_unique_id().await?;
        let workspace_id = workspace_id_int.to_string(); // Use the int as string for consistency

        conn.execute(
            r#"
            INSERT INTO workspace (workspace_id, project_id, name, path, current_branch, created_at, updated_at, metadata)
            VALUES (?, ?, ?, '', ?, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP, '{}')
            "#,
            [
                turso::Value::Text(workspace_id),
                turso::Value::Integer(project_id),
                turso::Value::Text(name.to_string()),
                turso::Value::Text(branch_hint.unwrap_or("").to_string()),
            ]
        )
        .await
        .map_err(|e| DatabaseError::OperationFailed {
            message: format!("Failed to create workspace: {}", e),
        })?;

        pool.return_connection(conn);
        Ok(workspace_id_int)
    }

    async fn get_workspace(&self, workspace_id: i64) -> Result<Option<Workspace>, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let workspace_id_str = workspace_id.to_string();
        let mut rows = conn
            .query(
                r#"
                SELECT w.workspace_id, w.project_id, w.name, '' as description, 
                       w.current_branch, 1 as is_active, w.created_at
                FROM workspace w 
                WHERE w.workspace_id = ?
                "#,
                [turso::Value::Text(workspace_id_str)],
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to get workspace: {}", e),
            })?;

        let result = if let Some(row) =
            rows.next()
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to iterate workspace results: {}", e),
                })? {
            Some(Workspace {
                workspace_id,
                project_id: match row.get_value(1) {
                    Ok(turso::Value::Integer(id)) => id,
                    _ => {
                        return Err(DatabaseError::OperationFailed {
                            message: "Invalid project_id in workspace".to_string(),
                        })
                    }
                },
                name: match row.get_value(2) {
                    Ok(turso::Value::Text(name)) => name,
                    _ => {
                        return Err(DatabaseError::OperationFailed {
                            message: "Invalid name in workspace".to_string(),
                        })
                    }
                },
                description: match row.get_value(3) {
                    Ok(turso::Value::Text(desc)) if !desc.is_empty() => Some(desc),
                    _ => None,
                },
                branch_hint: match row.get_value(4) {
                    Ok(turso::Value::Text(branch)) if !branch.is_empty() => Some(branch),
                    _ => None,
                },
                is_active: match row.get_value(5) {
                    Ok(turso::Value::Integer(active)) => active != 0,
                    _ => true,
                },
                created_at: match row.get_value(6) {
                    Ok(turso::Value::Text(created)) => created,
                    _ => "unknown".to_string(),
                },
            })
        } else {
            None
        };

        pool.return_connection(conn);
        Ok(result)
    }

    async fn list_workspaces(
        &self,
        project_id: Option<i64>,
    ) -> Result<Vec<Workspace>, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let (sql, params) = if let Some(proj_id) = project_id {
            (
                r#"
                SELECT w.workspace_id, w.project_id, w.name, '' as description,
                       w.current_branch, 1 as is_active, w.created_at
                FROM workspace w 
                WHERE w.project_id = ?
                ORDER BY w.created_at DESC
                "#,
                vec![turso::Value::Integer(proj_id)],
            )
        } else {
            (
                r#"
                SELECT w.workspace_id, w.project_id, w.name, '' as description,
                       w.current_branch, 1 as is_active, w.created_at
                FROM workspace w 
                ORDER BY w.created_at DESC
                "#,
                Vec::new(),
            )
        };

        let mut rows =
            conn.query(sql, params)
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to list workspaces: {}", e),
                })?;

        let mut workspaces = Vec::new();
        while let Some(row) = rows
            .next()
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to iterate workspace results: {}", e),
            })?
        {
            let workspace_id = match row.get_value(0) {
                Ok(turso::Value::Text(id_str)) => id_str.parse::<i64>().unwrap_or(0),
                Ok(turso::Value::Integer(id)) => id,
                _ => continue,
            };

            workspaces.push(Workspace {
                workspace_id,
                project_id: match row.get_value(1) {
                    Ok(turso::Value::Integer(id)) => id,
                    _ => continue,
                },
                name: match row.get_value(2) {
                    Ok(turso::Value::Text(name)) => name,
                    _ => continue,
                },
                description: match row.get_value(3) {
                    Ok(turso::Value::Text(desc)) if !desc.is_empty() => Some(desc),
                    _ => None,
                },
                branch_hint: match row.get_value(4) {
                    Ok(turso::Value::Text(branch)) if !branch.is_empty() => Some(branch),
                    _ => None,
                },
                is_active: match row.get_value(5) {
                    Ok(turso::Value::Integer(active)) => active != 0,
                    _ => true,
                },
                created_at: match row.get_value(6) {
                    Ok(turso::Value::Text(created)) => created,
                    _ => "unknown".to_string(),
                },
            });
        }

        pool.return_connection(conn);
        Ok(workspaces)
    }

    async fn update_workspace_branch(
        &self,
        workspace_id: i64,
        branch: &str,
    ) -> Result<(), DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let workspace_id_str = workspace_id.to_string();
        conn.execute(
            "UPDATE workspace SET current_branch = ?, updated_at = CURRENT_TIMESTAMP WHERE workspace_id = ?",
            [
                turso::Value::Text(branch.to_string()),
                turso::Value::Text(workspace_id_str),
            ]
        )
        .await
        .map_err(|e| DatabaseError::OperationFailed {
            message: format!("Failed to update workspace branch: {}", e),
        })?;

        pool.return_connection(conn);
        Ok(())
    }

    // ===================
    // File Version Management
    // ===================

    async fn create_file_version(
        &self,
        file_id: i64,
        content_digest: &str,
        size_bytes: u64,
        mtime: Option<i64>,
    ) -> Result<i64, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let version_id = uuid::Uuid::new_v4().to_string();
        let version_id_int = self.generate_unique_id().await?;

        let mtime_timestamp = mtime.map(|m| m.to_string());

        conn.execute(
            r#"
            INSERT INTO file_version (version_id, file_id, content_hash, size_bytes, last_modified, indexed_at)
            VALUES (?, ?, ?, ?, ?, CURRENT_TIMESTAMP)
            "#,
            [
                turso::Value::Text(version_id),
                turso::Value::Text(file_id.to_string()),
                turso::Value::Text(content_digest.to_string()),
                turso::Value::Integer(size_bytes as i64),
                mtime_timestamp.map(turso::Value::Text).unwrap_or(turso::Value::Null),
            ]
        )
        .await
        .map_err(|e| DatabaseError::OperationFailed {
            message: format!("Failed to create file version: {}", e),
        })?;

        pool.return_connection(conn);
        Ok(version_id_int)
    }

    async fn get_file_version_by_digest(
        &self,
        content_digest: &str,
    ) -> Result<Option<FileVersion>, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let mut rows = conn
            .query(
                r#"
                SELECT version_id, file_id, content_hash, git_commit_hash, size_bytes, 
                       line_count, last_modified
                FROM file_version
                WHERE content_hash = ?
                LIMIT 1
                "#,
                [turso::Value::Text(content_digest.to_string())],
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to get file version by digest: {}", e),
            })?;

        let result = if let Some(row) =
            rows.next()
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to iterate file version results: {}", e),
                })? {
            let version_id_str = match row.get_value(0) {
                Ok(turso::Value::Text(id)) => id,
                _ => {
                    return Err(DatabaseError::OperationFailed {
                        message: "Invalid version_id in file_version".to_string(),
                    })
                }
            };
            let version_id_int = version_id_str.parse::<i64>().unwrap_or(0);

            Some(FileVersion {
                file_version_id: version_id_int,
                file_id: match row.get_value(1) {
                    Ok(turso::Value::Text(id)) => id.parse::<i64>().unwrap_or(0),
                    Ok(turso::Value::Integer(id)) => id,
                    _ => 0,
                },
                content_digest: match row.get_value(2) {
                    Ok(turso::Value::Text(digest)) => digest,
                    _ => content_digest.to_string(),
                },
                git_blob_oid: match row.get_value(3) {
                    Ok(turso::Value::Text(oid)) if !oid.is_empty() => Some(oid),
                    _ => None,
                },
                size_bytes: match row.get_value(4) {
                    Ok(turso::Value::Integer(size)) => size as u64,
                    _ => 0,
                },
                line_count: match row.get_value(5) {
                    Ok(turso::Value::Integer(count)) => Some(count as u32),
                    _ => None,
                },
                detected_language: None, // Not stored in file_version table
                mtime: match row.get_value(6) {
                    Ok(turso::Value::Text(mtime_str)) => mtime_str.parse::<i64>().ok(),
                    Ok(turso::Value::Integer(mtime)) => Some(mtime),
                    _ => None,
                },
            })
        } else {
            None
        };

        pool.return_connection(conn);
        Ok(result)
    }

    async fn link_file_to_workspace(
        &self,
        workspace_id: i64,
        file_id: i64,
        _file_version_id: i64,
    ) -> Result<(), DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let workspace_file_id = uuid::Uuid::new_v4().to_string();

        conn.execute(
            r#"
            INSERT INTO workspace_file (workspace_file_id, workspace_id, file_id, is_active, added_at)
            VALUES (?, ?, ?, 1, CURRENT_TIMESTAMP)
            "#,
            [
                turso::Value::Text(workspace_file_id),
                turso::Value::Text(workspace_id.to_string()),
                turso::Value::Text(file_id.to_string()),
            ]
        )
        .await
        .map_err(|e| DatabaseError::OperationFailed {
            message: format!("Failed to link file to workspace: {}", e),
        })?;

        pool.return_connection(conn);
        Ok(())
    }

    // ===================
    // Symbol Storage & Retrieval
    // ===================

    async fn store_symbols(&self, symbols: &[SymbolState]) -> Result<(), DatabaseError> {
        if symbols.is_empty() {
            return Ok(());
        }

        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        // Use transaction for batch operations with rollback on error
        conn.execute("BEGIN TRANSACTION", ()).await.map_err(|e| {
            DatabaseError::OperationFailed {
                message: format!("Failed to begin transaction for symbols: {}", e),
            }
        })?;

        // Batch size for optimal performance
        const BATCH_SIZE: usize = 100;

        for chunk in symbols.chunks(BATCH_SIZE) {
            // Prepare batch insert queries
            let symbols_placeholders = chunk.iter()
                .map(|_| "(?, 1, ?, ?, ?, ?, 'unknown', ?, ?, ?, ?, ?, ?, ?, '', CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)")
                .collect::<Vec<_>>()
                .join(", ");

            let states_placeholders = chunk
                .iter()
                .map(|_| "(?, ?, ?, ?, CURRENT_TIMESTAMP, 1.0)")
                .collect::<Vec<_>>()
                .join(", ");

            // Prepare batch parameters for symbols
            let mut symbol_params = Vec::new();
            let mut symbol_ids = Vec::new();

            for symbol in chunk {
                let symbol_id = uuid::Uuid::new_v4().to_string();
                symbol_ids.push(symbol_id.clone());

                symbol_params.extend(vec![
                    turso::Value::Text(symbol_id),
                    turso::Value::Text(symbol.file_version_id.to_string()),
                    turso::Value::Text(symbol.name.clone()),
                    symbol
                        .fqn
                        .as_ref()
                        .map(|s| turso::Value::Text(s.clone()))
                        .unwrap_or(turso::Value::Null),
                    turso::Value::Text(symbol.kind.clone()),
                    turso::Value::Integer(symbol.def_start_line as i64),
                    turso::Value::Integer(symbol.def_start_char as i64),
                    turso::Value::Integer(symbol.def_end_line as i64),
                    turso::Value::Integer(symbol.def_end_char as i64),
                    symbol
                        .signature
                        .as_ref()
                        .map(|s| turso::Value::Text(s.clone()))
                        .unwrap_or(turso::Value::Null),
                    symbol
                        .documentation
                        .as_ref()
                        .map(|s| turso::Value::Text(s.clone()))
                        .unwrap_or(turso::Value::Null),
                    symbol
                        .visibility
                        .as_ref()
                        .map(|s| turso::Value::Text(s.clone()))
                        .unwrap_or(turso::Value::Null),
                ]);
            }

            // Batch insert symbols
            let batch_symbol_sql = format!(
                "INSERT INTO symbol (symbol_id, project_id, file_id, name, qualified_name, symbol_type, language, start_line, start_column, end_line, end_column, signature, documentation, visibility, modifiers, created_at, updated_at) VALUES {}",
                symbols_placeholders
            );

            conn.execute(&batch_symbol_sql, symbol_params)
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to batch insert symbols: {}", e),
                })?;

            // Prepare batch parameters for symbol states
            let mut state_params = Vec::new();

            for (i, symbol) in chunk.iter().enumerate() {
                let state_id = uuid::Uuid::new_v4().to_string();
                let definition_data = serde_json::json!({
                    "is_definition": symbol.is_definition,
                    "metadata": symbol.metadata
                })
                .to_string();

                state_params.extend(vec![
                    turso::Value::Text(state_id),
                    turso::Value::Text(symbol_ids[i].clone()),
                    turso::Value::Text(symbol.file_version_id.to_string()),
                    turso::Value::Text(definition_data),
                ]);
            }

            // Batch insert symbol states
            let batch_state_sql = format!(
                "INSERT INTO symbol_state (state_id, symbol_id, version_id, definition_data, indexed_at, confidence) VALUES {}",
                states_placeholders
            );

            conn.execute(&batch_state_sql, state_params)
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to batch insert symbol states: {}", e),
                })?;
        }

        // Commit transaction
        conn.execute("COMMIT", ())
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to commit symbol transaction: {}", e),
            })?;

        pool.return_connection(conn);
        Ok(())
    }

    async fn get_symbols_by_file(
        &self,
        file_version_id: i64,
        language: &str,
    ) -> Result<Vec<SymbolState>, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let mut rows = conn
            .query(
                r#"
                SELECT s.symbol_id, s.name, s.qualified_name, s.symbol_type,
                       s.start_line, s.start_column, s.end_line, s.end_column,
                       s.signature, s.documentation, s.visibility,
                       ss.definition_data
                FROM symbol s
                JOIN symbol_state ss ON s.symbol_id = ss.symbol_id
                WHERE ss.version_id = ?
                "#,
                [turso::Value::Text(file_version_id.to_string())],
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to get symbols by file: {}", e),
            })?;

        let mut symbols = Vec::new();
        while let Some(row) = rows
            .next()
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to iterate symbol results: {}", e),
            })?
        {
            let symbol_uid = match row.get_value(0) {
                Ok(turso::Value::Text(uid)) => uid,
                _ => continue,
            };

            let definition_data_str = match row.get_value(11) {
                Ok(turso::Value::Text(data)) => data,
                _ => "{}".to_string(),
            };

            let definition_data: serde_json::Value = serde_json::from_str(&definition_data_str)
                .unwrap_or_else(|_| serde_json::json!({}));

            symbols.push(SymbolState {
                symbol_uid,
                file_version_id,
                language: language.to_string(),
                name: match row.get_value(1) {
                    Ok(turso::Value::Text(name)) => name,
                    _ => continue,
                },
                fqn: match row.get_value(2) {
                    Ok(turso::Value::Text(fqn)) if !fqn.is_empty() => Some(fqn),
                    _ => None,
                },
                kind: match row.get_value(3) {
                    Ok(turso::Value::Text(kind)) => kind,
                    _ => "unknown".to_string(),
                },
                signature: match row.get_value(8) {
                    Ok(turso::Value::Text(sig)) if !sig.is_empty() => Some(sig),
                    _ => None,
                },
                visibility: match row.get_value(10) {
                    Ok(turso::Value::Text(vis)) if !vis.is_empty() => Some(vis),
                    _ => None,
                },
                def_start_line: match row.get_value(4) {
                    Ok(turso::Value::Integer(line)) => line as u32,
                    _ => 0,
                },
                def_start_char: match row.get_value(5) {
                    Ok(turso::Value::Integer(char)) => char as u32,
                    _ => 0,
                },
                def_end_line: match row.get_value(6) {
                    Ok(turso::Value::Integer(line)) => line as u32,
                    _ => 0,
                },
                def_end_char: match row.get_value(7) {
                    Ok(turso::Value::Integer(char)) => char as u32,
                    _ => 0,
                },
                is_definition: definition_data
                    .get("is_definition")
                    .and_then(|v| v.as_bool())
                    .unwrap_or(true),
                documentation: match row.get_value(9) {
                    Ok(turso::Value::Text(doc)) if !doc.is_empty() => Some(doc),
                    _ => None,
                },
                metadata: definition_data
                    .get("metadata")
                    .and_then(|v| v.as_str())
                    .map(|s| s.to_string()),
            });
        }

        pool.return_connection(conn);
        Ok(symbols)
    }

    async fn find_symbol_by_name(
        &self,
        _workspace_id: i64,
        name: &str,
    ) -> Result<Vec<SymbolState>, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let mut rows = conn
            .query(
                r#"
                SELECT s.symbol_id, s.name, s.qualified_name, s.symbol_type,
                       s.start_line, s.start_column, s.end_line, s.end_column,
                       s.signature, s.documentation, s.visibility,
                       ss.definition_data, ss.version_id
                FROM symbol s
                JOIN symbol_state ss ON s.symbol_id = ss.symbol_id
                WHERE s.name = ?
                "#,
                [turso::Value::Text(name.to_string())],
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to find symbol by name: {}", e),
            })?;

        let mut symbols = Vec::new();
        while let Some(row) = rows
            .next()
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to iterate symbol search results: {}", e),
            })?
        {
            let symbol_uid = match row.get_value(0) {
                Ok(turso::Value::Text(uid)) => uid,
                _ => continue,
            };

            let definition_data_str = match row.get_value(11) {
                Ok(turso::Value::Text(data)) => data,
                _ => "{}".to_string(),
            };

            let definition_data: serde_json::Value = serde_json::from_str(&definition_data_str)
                .unwrap_or_else(|_| serde_json::json!({}));

            let file_version_id = match row.get_value(12) {
                Ok(turso::Value::Text(id)) => id.parse::<i64>().unwrap_or(0),
                Ok(turso::Value::Integer(id)) => id,
                _ => 0,
            };

            symbols.push(SymbolState {
                symbol_uid,
                file_version_id,
                language: "unknown".to_string(), // Will be updated by caller
                name: name.to_string(),
                fqn: match row.get_value(2) {
                    Ok(turso::Value::Text(fqn)) if !fqn.is_empty() => Some(fqn),
                    _ => None,
                },
                kind: match row.get_value(3) {
                    Ok(turso::Value::Text(kind)) => kind,
                    _ => "unknown".to_string(),
                },
                signature: match row.get_value(8) {
                    Ok(turso::Value::Text(sig)) if !sig.is_empty() => Some(sig),
                    _ => None,
                },
                visibility: match row.get_value(10) {
                    Ok(turso::Value::Text(vis)) if !vis.is_empty() => Some(vis),
                    _ => None,
                },
                def_start_line: match row.get_value(4) {
                    Ok(turso::Value::Integer(line)) => line as u32,
                    _ => 0,
                },
                def_start_char: match row.get_value(5) {
                    Ok(turso::Value::Integer(char)) => char as u32,
                    _ => 0,
                },
                def_end_line: match row.get_value(6) {
                    Ok(turso::Value::Integer(line)) => line as u32,
                    _ => 0,
                },
                def_end_char: match row.get_value(7) {
                    Ok(turso::Value::Integer(char)) => char as u32,
                    _ => 0,
                },
                is_definition: definition_data
                    .get("is_definition")
                    .and_then(|v| v.as_bool())
                    .unwrap_or(true),
                documentation: match row.get_value(9) {
                    Ok(turso::Value::Text(doc)) if !doc.is_empty() => Some(doc),
                    _ => None,
                },
                metadata: definition_data
                    .get("metadata")
                    .and_then(|v| v.as_str())
                    .map(|s| s.to_string()),
            });
        }

        pool.return_connection(conn);
        Ok(symbols)
    }

    async fn find_symbol_by_fqn(
        &self,
        _workspace_id: i64,
        fqn: &str,
    ) -> Result<Option<SymbolState>, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let mut rows = conn
            .query(
                r#"
                SELECT s.symbol_id, s.name, s.qualified_name, s.symbol_type,
                       s.start_line, s.start_column, s.end_line, s.end_column,
                       s.signature, s.documentation, s.visibility,
                       ss.definition_data, ss.version_id
                FROM symbol s
                JOIN symbol_state ss ON s.symbol_id = ss.symbol_id
                WHERE s.qualified_name = ?
                LIMIT 1
                "#,
                [turso::Value::Text(fqn.to_string())],
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to find symbol by FQN: {}", e),
            })?;

        let result = if let Some(row) =
            rows.next()
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to iterate FQN symbol results: {}", e),
                })? {
            let symbol_uid = match row.get_value(0) {
                Ok(turso::Value::Text(uid)) => uid,
                _ => return Ok(None),
            };

            let definition_data_str = match row.get_value(11) {
                Ok(turso::Value::Text(data)) => data,
                _ => "{}".to_string(),
            };

            let definition_data: serde_json::Value = serde_json::from_str(&definition_data_str)
                .unwrap_or_else(|_| serde_json::json!({}));

            let file_version_id = match row.get_value(12) {
                Ok(turso::Value::Text(id)) => id.parse::<i64>().unwrap_or(0),
                Ok(turso::Value::Integer(id)) => id,
                _ => 0,
            };

            Some(SymbolState {
                symbol_uid,
                file_version_id,
                language: "unknown".to_string(), // Will be updated by caller
                name: match row.get_value(1) {
                    Ok(turso::Value::Text(name)) => name,
                    _ => "unknown".to_string(),
                },
                fqn: Some(fqn.to_string()),
                kind: match row.get_value(3) {
                    Ok(turso::Value::Text(kind)) => kind,
                    _ => "unknown".to_string(),
                },
                signature: match row.get_value(8) {
                    Ok(turso::Value::Text(sig)) if !sig.is_empty() => Some(sig),
                    _ => None,
                },
                visibility: match row.get_value(10) {
                    Ok(turso::Value::Text(vis)) if !vis.is_empty() => Some(vis),
                    _ => None,
                },
                def_start_line: match row.get_value(4) {
                    Ok(turso::Value::Integer(line)) => line as u32,
                    _ => 0,
                },
                def_start_char: match row.get_value(5) {
                    Ok(turso::Value::Integer(char)) => char as u32,
                    _ => 0,
                },
                def_end_line: match row.get_value(6) {
                    Ok(turso::Value::Integer(line)) => line as u32,
                    _ => 0,
                },
                def_end_char: match row.get_value(7) {
                    Ok(turso::Value::Integer(char)) => char as u32,
                    _ => 0,
                },
                is_definition: definition_data
                    .get("is_definition")
                    .and_then(|v| v.as_bool())
                    .unwrap_or(true),
                documentation: match row.get_value(9) {
                    Ok(turso::Value::Text(doc)) if !doc.is_empty() => Some(doc),
                    _ => None,
                },
                metadata: definition_data
                    .get("metadata")
                    .and_then(|v| v.as_str())
                    .map(|s| s.to_string()),
            })
        } else {
            None
        };

        pool.return_connection(conn);
        Ok(result)
    }

    // ===================
    // Relationship Storage & Querying
    // ===================

    async fn store_edges(&self, edges: &[Edge]) -> Result<(), DatabaseError> {
        if edges.is_empty() {
            return Ok(());
        }

        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        // Use transaction for batch operations with rollback on error
        conn.execute("BEGIN TRANSACTION", ()).await.map_err(|e| {
            DatabaseError::OperationFailed {
                message: format!("Failed to begin transaction for edges: {}", e),
            }
        })?;

        // Batch size for optimal performance - edges are smaller so we can handle more
        const BATCH_SIZE: usize = 200;

        for chunk in edges.chunks(BATCH_SIZE) {
            // Prepare batch insert query
            let placeholders = chunk
                .iter()
                .map(|_| "(?, 1, ?, ?, ?, ?, ?, ?, ?, ?, CURRENT_TIMESTAMP)")
                .collect::<Vec<_>>()
                .join(", ");

            // Prepare batch parameters
            let mut params = Vec::new();

            for edge in chunk {
                let edge_id = uuid::Uuid::new_v4().to_string();

                params.extend(vec![
                    turso::Value::Text(edge_id),
                    turso::Value::Text(edge.source_symbol_uid.clone()),
                    turso::Value::Text(edge.target_symbol_uid.clone()),
                    turso::Value::Text(edge.relation.to_string().to_string()),
                    turso::Value::Text(edge.anchor_file_version_id.to_string()), // Using as file_id
                    turso::Value::Text(edge.anchor_file_version_id.to_string()),
                    edge.start_line
                        .map(|l| turso::Value::Text(l.to_string()))
                        .unwrap_or(turso::Value::Null),
                    edge.start_char
                        .map(|c| turso::Value::Text(c.to_string()))
                        .unwrap_or(turso::Value::Null),
                    turso::Value::Real(edge.confidence as f64),
                ]);
            }

            // Execute batch insert
            let batch_sql = format!(
                "INSERT INTO edge (edge_id, project_id, source_symbol_id, target_symbol_id, edge_type, file_id, version_id, source_location, target_location, confidence, created_at) VALUES {}",
                placeholders
            );

            conn.execute(&batch_sql, params)
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to batch insert edges: {}", e),
                })?;
        }

        // Commit transaction
        conn.execute("COMMIT", ())
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to commit edge transaction: {}", e),
            })?;

        pool.return_connection(conn);
        Ok(())
    }

    async fn get_symbol_references(
        &self,
        _workspace_id: i64,
        symbol_uid: &str,
    ) -> Result<Vec<Edge>, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let mut rows = conn
            .query(
                r#"
                SELECT source_symbol_uid, target_symbol_uid, relation, anchor_file_version_id,
                       start_line, start_char, confidence
                FROM edge
                WHERE target_symbol_uid = ?
                "#,
                [turso::Value::Text(symbol_uid.to_string())],
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to get symbol references: {}", e),
            })?;

        let mut edges = Vec::new();
        while let Some(row) = rows
            .next()
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to iterate reference results: {}", e),
            })?
        {
            let relation_str = match row.get_value(2) {
                Ok(turso::Value::Text(rel)) => rel,
                _ => continue,
            };

            let relation = match crate::database::EdgeRelation::from_string(&relation_str) {
                Ok(rel) => rel,
                Err(_) => continue,
            };

            edges.push(Edge {
                language: "unknown".to_string(), // Will be updated by caller
                relation,
                source_symbol_uid: match row.get_value(0) {
                    Ok(turso::Value::Text(uid)) => uid,
                    _ => continue,
                },
                target_symbol_uid: match row.get_value(1) {
                    Ok(turso::Value::Text(uid)) => uid,
                    _ => continue,
                },
                anchor_file_version_id: match row.get_value(3) {
                    Ok(turso::Value::Text(id)) => id.parse::<i64>().unwrap_or(0),
                    Ok(turso::Value::Integer(id)) => id,
                    _ => 0,
                },
                start_line: match row.get_value(4) {
                    Ok(turso::Value::Text(line)) => line.parse::<u32>().ok(),
                    Ok(turso::Value::Integer(line)) => Some(line as u32),
                    _ => None,
                },
                start_char: match row.get_value(5) {
                    Ok(turso::Value::Text(char)) => char.parse::<u32>().ok(),
                    Ok(turso::Value::Integer(char)) => Some(char as u32),
                    _ => None,
                },
                confidence: match row.get_value(6) {
                    Ok(turso::Value::Real(conf)) => conf as f32,
                    Ok(turso::Value::Integer(conf)) => conf as f32,
                    _ => 1.0,
                },
                metadata: None,
            });
        }

        pool.return_connection(conn);
        Ok(edges)
    }

    async fn get_symbol_calls(
        &self,
        _workspace_id: i64,
        symbol_uid: &str,
        direction: CallDirection,
    ) -> Result<Vec<Edge>, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let (sql, params) = match direction {
            CallDirection::Incoming => (
                r#"
                SELECT source_symbol_id, target_symbol_id, edge_type, version_id,
                       source_location, target_location, confidence
                FROM edge
                WHERE target_symbol_id = ? AND edge_type = 'calls'
                "#,
                vec![turso::Value::Text(symbol_uid.to_string())],
            ),
            CallDirection::Outgoing => (
                r#"
                SELECT source_symbol_id, target_symbol_id, edge_type, version_id,
                       source_location, target_location, confidence
                FROM edge
                WHERE source_symbol_id = ? AND edge_type = 'calls'
                "#,
                vec![turso::Value::Text(symbol_uid.to_string())],
            ),
            CallDirection::Both => (
                r#"
                SELECT source_symbol_id, target_symbol_id, edge_type, version_id,
                       source_location, target_location, confidence
                FROM edge
                WHERE (source_symbol_id = ? OR target_symbol_id = ?) AND edge_type = 'calls'
                "#,
                vec![
                    turso::Value::Text(symbol_uid.to_string()),
                    turso::Value::Text(symbol_uid.to_string()),
                ],
            ),
        };

        let mut rows =
            conn.query(sql, params)
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to get symbol calls: {}", e),
                })?;

        let mut edges = Vec::new();
        while let Some(row) = rows
            .next()
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to iterate call results: {}", e),
            })?
        {
            let relation = crate::database::EdgeRelation::Calls;

            edges.push(Edge {
                language: "unknown".to_string(), // Will be updated by caller
                relation,
                source_symbol_uid: match row.get_value(0) {
                    Ok(turso::Value::Text(uid)) => uid,
                    _ => continue,
                },
                target_symbol_uid: match row.get_value(1) {
                    Ok(turso::Value::Text(uid)) => uid,
                    _ => continue,
                },
                anchor_file_version_id: match row.get_value(3) {
                    Ok(turso::Value::Text(id)) => id.parse::<i64>().unwrap_or(0),
                    Ok(turso::Value::Integer(id)) => id,
                    _ => 0,
                },
                start_line: match row.get_value(4) {
                    Ok(turso::Value::Text(line)) => line.parse::<u32>().ok(),
                    Ok(turso::Value::Integer(line)) => Some(line as u32),
                    _ => None,
                },
                start_char: match row.get_value(5) {
                    Ok(turso::Value::Text(char)) => char.parse::<u32>().ok(),
                    Ok(turso::Value::Integer(char)) => Some(char as u32),
                    _ => None,
                },
                confidence: match row.get_value(6) {
                    Ok(turso::Value::Real(conf)) => conf as f32,
                    Ok(turso::Value::Integer(conf)) => conf as f32,
                    _ => 1.0,
                },
                metadata: None,
            });
        }

        pool.return_connection(conn);
        Ok(edges)
    }

    async fn traverse_graph(
        &self,
        start_symbol: &str,
        max_depth: u32,
        relations: &[EdgeRelation],
    ) -> Result<Vec<GraphPath>, DatabaseError> {
        // This is a simplified implementation of graph traversal
        // In a production system, this would use a more sophisticated graph algorithm

        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        // Convert relations to string for SQL query
        let relation_strs: Vec<String> = relations
            .iter()
            .map(|r| r.to_string().to_string())
            .collect();

        if relation_strs.is_empty() {
            pool.return_connection(conn);
            return Ok(Vec::new());
        }

        // For simplicity, we'll do a breadth-first traversal up to max_depth
        let mut paths = Vec::new();
        let mut current_depth = 0;
        let mut current_symbols = vec![start_symbol.to_string()];

        while current_depth < max_depth && !current_symbols.is_empty() {
            let mut next_symbols = Vec::new();

            for symbol in &current_symbols {
                // Build placeholders for the IN clause
                let placeholders = relation_strs
                    .iter()
                    .map(|_| "?")
                    .collect::<Vec<_>>()
                    .join(",");
                let sql = format!(
                    r#"
                    SELECT target_symbol_id, edge_type
                    FROM edge
                    WHERE source_symbol_id = ? AND edge_type IN ({})
                    "#,
                    placeholders
                );

                let mut params = vec![turso::Value::Text(symbol.clone())];
                for rel_str in &relation_strs {
                    params.push(turso::Value::Text(rel_str.clone()));
                }

                let mut rows =
                    conn.query(&sql, params)
                        .await
                        .map_err(|e| DatabaseError::OperationFailed {
                            message: format!("Failed to traverse graph: {}", e),
                        })?;

                while let Some(row) =
                    rows.next()
                        .await
                        .map_err(|e| DatabaseError::OperationFailed {
                            message: format!("Failed to iterate traversal results: {}", e),
                        })?
                {
                    let target_symbol = match row.get_value(0) {
                        Ok(turso::Value::Text(uid)) => uid,
                        _ => continue,
                    };

                    let edge_type_str = match row.get_value(1) {
                        Ok(turso::Value::Text(edge_type)) => edge_type,
                        _ => continue,
                    };

                    if let Ok(relation) = crate::database::EdgeRelation::from_string(&edge_type_str)
                    {
                        let path = GraphPath {
                            symbol_uid: target_symbol.clone(),
                            depth: current_depth + 1,
                            path: vec![start_symbol.to_string(), target_symbol.clone()],
                            relation_chain: vec![relation],
                        };
                        paths.push(path);
                        next_symbols.push(target_symbol);
                    }
                }
            }

            current_symbols = next_symbols;
            current_depth += 1;
        }

        pool.return_connection(conn);
        Ok(paths)
    }

    // ===================
    // Analysis Management
    // ===================

    async fn create_analysis_run(
        &self,
        analyzer_name: &str,
        analyzer_version: &str,
        _language: &str,
        config: &str,
    ) -> Result<i64, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let run_id = uuid::Uuid::new_v4().to_string();
        let run_id_int = self.generate_unique_id().await?;

        conn.execute(
            r#"
            INSERT INTO analysis_run (
                run_id, workspace_id, analyzer_type, analyzer_version,
                configuration, started_at, status
            )
            VALUES (?, '1', ?, ?, ?, CURRENT_TIMESTAMP, 'running')
            "#,
            [
                turso::Value::Text(run_id),
                turso::Value::Text(analyzer_name.to_string()),
                turso::Value::Text(analyzer_version.to_string()),
                turso::Value::Text(config.to_string()),
            ],
        )
        .await
        .map_err(|e| DatabaseError::OperationFailed {
            message: format!("Failed to create analysis run: {}", e),
        })?;

        pool.return_connection(conn);
        Ok(run_id_int)
    }

    async fn get_analysis_progress(
        &self,
        workspace_id: i64,
    ) -> Result<AnalysisProgress, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let workspace_id_str = workspace_id.to_string();

        // Get counts from analysis_run and file_analysis tables
        let mut rows = conn
            .query(
                r#"
                SELECT 
                    COALESCE(SUM(ar.files_processed), 0) as total_processed,
                    COUNT(DISTINCT ar.run_id) as total_runs
                FROM analysis_run ar
                WHERE ar.workspace_id = ?
                "#,
                [turso::Value::Text(workspace_id_str.clone())],
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to get analysis progress: {}", e),
            })?;

        let (analyzed_files, _total_runs) = if let Some(row) =
            rows.next()
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to iterate analysis progress results: {}", e),
                })? {
            (
                match row.get_value(0) {
                    Ok(turso::Value::Integer(count)) => count as u64,
                    _ => 0,
                },
                match row.get_value(1) {
                    Ok(turso::Value::Integer(count)) => count as u64,
                    _ => 0,
                },
            )
        } else {
            (0, 0)
        };

        // Get real progress from workspace file analysis and indexer queue
        let mut progress_rows = conn
            .query(
                r#"
                WITH workspace_files AS (
                    SELECT COUNT(*) as total_workspace_files
                    FROM workspace_file wf
                    WHERE wf.workspace_id = ? AND wf.is_active = 1
                ),
                analyzed_files AS (
                    SELECT 
                        COUNT(CASE WHEN wfa.analysis_status = 'completed' THEN 1 END) as successful_files,
                        COUNT(CASE WHEN wfa.analysis_status = 'failed' THEN 1 END) as failed_files,
                        COUNT(CASE WHEN wfa.analysis_status = 'pending' OR wfa.analysis_status = 'running' THEN 1 END) as pending_files
                    FROM workspace_file_analysis wfa
                    JOIN workspace_file wf ON wfa.workspace_file_id = wf.workspace_file_id
                    WHERE wf.workspace_id = ? AND wf.is_active = 1
                ),
                queued_files AS (
                    SELECT COUNT(*) as queued_count
                    FROM indexer_queue iq
                    JOIN file_version fv ON iq.file_version_id = fv.version_id
                    JOIN file f ON fv.file_id = f.file_id
                    JOIN workspace_file wf ON f.file_id = wf.file_id
                    WHERE wf.workspace_id = ? AND wf.is_active = 1 AND iq.status = 'pending'
                )
                SELECT 
                    COALESCE(wf.total_workspace_files, 0) as total_files,
                    COALESCE(af.successful_files, 0) as successful_files,
                    COALESCE(af.failed_files, 0) as failed_files,
                    COALESCE(af.pending_files + q.queued_count, 0) as pending_files
                FROM workspace_files wf
                CROSS JOIN analyzed_files af
                CROSS JOIN queued_files q
                "#,
                [
                    turso::Value::Text(workspace_id_str.clone()),
                    turso::Value::Text(workspace_id_str.clone()),
                    turso::Value::Text(workspace_id_str.clone())
                ]
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to get detailed analysis progress: {}", e),
            })?;

        let (total_files, analyzed_files, failed_files, pending_files) = if let Some(row) =
            progress_rows
                .next()
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to iterate detailed progress results: {}", e),
                })? {
            (
                match row.get_value(0) {
                    Ok(turso::Value::Integer(count)) => count as u64,
                    _ => 0,
                },
                match row.get_value(1) {
                    Ok(turso::Value::Integer(count)) => count as u64,
                    _ => 0,
                },
                match row.get_value(2) {
                    Ok(turso::Value::Integer(count)) => count as u64,
                    _ => 0,
                },
                match row.get_value(3) {
                    Ok(turso::Value::Integer(count)) => count as u64,
                    _ => 0,
                },
            )
        } else {
            // Fallback: use analyzed_files from the previous query as total if detailed data isn't available
            let total = analyzed_files.max(1); // Ensure at least 1 to avoid division by zero
            (
                total,
                analyzed_files,
                0,
                if total > analyzed_files {
                    total - analyzed_files
                } else {
                    0
                },
            )
        };

        let completion_percentage = if total_files > 0 {
            (analyzed_files as f32 / total_files as f32) * 100.0
        } else {
            0.0
        };

        pool.return_connection(conn);

        Ok(AnalysisProgress {
            workspace_id,
            total_files,
            analyzed_files,
            failed_files,
            pending_files,
            completion_percentage,
        })
    }

    async fn queue_file_analysis(
        &self,
        file_version_id: i64,
        _language: &str,
        priority: i32,
    ) -> Result<(), DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let queue_id = uuid::Uuid::new_v4().to_string();

        conn.execute(
            r#"
            INSERT INTO indexer_queue (
                queue_id, workspace_id, file_id, priority, operation_type,
                status, created_at
            )
            VALUES (?, '1', ?, ?, 'analyze', 'pending', CURRENT_TIMESTAMP)
            "#,
            [
                turso::Value::Text(queue_id),
                turso::Value::Text(file_version_id.to_string()),
                turso::Value::Integer(priority as i64),
            ],
        )
        .await
        .map_err(|e| DatabaseError::OperationFailed {
            message: format!("Failed to queue file analysis: {}", e),
        })?;

        pool.return_connection(conn);
        Ok(())
    }

    // Missing trait methods - temporary placeholder implementations
    async fn get_all_symbols(&self) -> Result<Vec<SymbolState>, DatabaseError> {
        // Placeholder implementation - would return all symbols from all workspaces
        eprintln!("DEBUG: get_all_symbols not yet implemented, returning empty list");
        Ok(Vec::new())
    }

    async fn get_all_edges(&self) -> Result<Vec<Edge>, DatabaseError> {
        // Placeholder implementation - would return all edges from all workspaces  
        eprintln!("DEBUG: get_all_edges not yet implemented, returning empty list");
        Ok(Vec::new())
    }


    // ===================
    // LSP Protocol Query Methods Implementation
    // ===================

    async fn get_call_hierarchy_for_symbol(
        &self,
        workspace_id: i64,
        symbol_uid: &str,
    ) -> Result<Option<CallHierarchyResult>, DatabaseError> {
        info!("[DEBUG] get_call_hierarchy_for_symbol ENTRY: workspace_id={}, symbol_uid={}", workspace_id, symbol_uid);
        
        // Step 25.3: Verify database connection
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await.map_err(|e| {
            error!("[DEBUG] Database connection failed: {}", e);
            e
        })?;
        debug!("[DEBUG] Database connection acquired successfully");
        
        // Step 25.5: Check if symbol_state table exists and has data
        let mut table_check = conn
            .query("SELECT COUNT(*) FROM symbol_state LIMIT 1", [] as [turso::Value; 0])
            .await
            .map_err(|e| {
                error!("[DEBUG] Failed to check symbol_state table existence: {}", e);
                DatabaseError::OperationFailed {
                    message: format!("Failed to check symbol_state table: {}", e),
                }
            })?;
        
        if let Some(row) = table_check.next().await.map_err(|e| {
            error!("[DEBUG] Failed to read table check result: {}", e);
            DatabaseError::OperationFailed {
                message: format!("Failed to read table check result: {}", e),
            }
        })? {
            let count = match row.get_value(0) {
                Ok(turso::Value::Integer(count)) => count,
                _ => -1,
            };
            info!("[DEBUG] symbol_state table has {} rows", count);
        }
        
        // Step 25.2: Log the SQL query being executed
        let query = "SELECT symbol_uid, file_version_id, language, name, fqn, kind, signature, visibility, def_start_line, def_start_char, def_end_line, def_end_char, is_definition, documentation, metadata FROM symbol_state WHERE symbol_uid = ?";
        info!("[DEBUG] Executing SQL query: {}", query);
        info!("[DEBUG] Query parameters: symbol_uid = '{}'", symbol_uid);
        
        // 1. Get the symbol details

        // Find the symbol by UID
        let mut symbol_rows = conn
            .query(
                query,
                [turso::Value::Text(symbol_uid.to_string())],
            )
            .await
            .map_err(|e| {
                error!("[DEBUG] SQL query execution failed: {}", e);
                DatabaseError::OperationFailed {
                    message: format!("Failed to find symbol by UID: {}", e),
                }
            })?;
        
        debug!("[DEBUG] SQL query executed successfully");

        let center_symbol = if let Some(row) = symbol_rows.next().await.map_err(|e| {
            error!("[DEBUG] Failed to iterate symbol results: {}", e);
            DatabaseError::OperationFailed {
                message: format!("Failed to iterate symbol results: {}", e),
            }
        })? {
            info!("[DEBUG] Found symbol row in database");
            SymbolState {
                symbol_uid: match row.get_value(0) {
                    Ok(turso::Value::Text(uid)) => uid,
                    _ => return Ok(None),
                },
                file_version_id: match row.get_value(1) {
                    Ok(turso::Value::Integer(id)) => id,
                    Ok(turso::Value::Text(id_str)) => id_str.parse::<i64>().unwrap_or(0),
                    _ => 0,
                },
                language: match row.get_value(2) {
                    Ok(turso::Value::Text(lang)) => lang,
                    _ => "unknown".to_string(),
                },
                name: match row.get_value(3) {
                    Ok(turso::Value::Text(name)) => name,
                    _ => "unknown".to_string(),
                },
                fqn: match row.get_value(4) {
                    Ok(turso::Value::Text(fqn)) => Some(fqn),
                    _ => None,
                },
                kind: match row.get_value(5) {
                    Ok(turso::Value::Text(kind)) => kind,
                    _ => "unknown".to_string(),
                },
                signature: match row.get_value(6) {
                    Ok(turso::Value::Text(sig)) => Some(sig),
                    _ => None,
                },
                visibility: match row.get_value(7) {
                    Ok(turso::Value::Text(vis)) => Some(vis),
                    _ => None,
                },
                def_start_line: match row.get_value(8) {
                    Ok(turso::Value::Integer(line)) => line as u32,
                    Ok(turso::Value::Text(line_str)) => line_str.parse::<u32>().unwrap_or(0),
                    _ => 0,
                },
                def_start_char: match row.get_value(9) {
                    Ok(turso::Value::Integer(char)) => char as u32,
                    Ok(turso::Value::Text(char_str)) => char_str.parse::<u32>().unwrap_or(0),
                    _ => 0,
                },
                def_end_line: match row.get_value(10) {
                    Ok(turso::Value::Integer(line)) => line as u32,
                    Ok(turso::Value::Text(line_str)) => line_str.parse::<u32>().unwrap_or(0),
                    _ => 0,
                },
                def_end_char: match row.get_value(11) {
                    Ok(turso::Value::Integer(char)) => char as u32,
                    Ok(turso::Value::Text(char_str)) => char_str.parse::<u32>().unwrap_or(0),
                    _ => 0,
                },
                is_definition: match row.get_value(12) {
                    Ok(turso::Value::Integer(val)) => val != 0,
                    Ok(turso::Value::Text(val)) => val.parse::<i32>().unwrap_or(0) != 0,
                    _ => false,
                },
                documentation: match row.get_value(13) {
                    Ok(turso::Value::Text(doc)) => Some(doc),
                    _ => None,
                },
                metadata: match row.get_value(14) {
                    Ok(turso::Value::Text(meta)) => Some(meta),
                    _ => None,
                },
            }
        } else {
            info!("[DEBUG] Symbol not found '{}' - auto-creating placeholder", symbol_uid);

            // Auto-create the missing symbol
            let placeholder_symbol = self.ensure_symbol_exists(
                workspace_id,
                symbol_uid,
                &PathBuf::from("unknown"), // Will be updated by LSP
                0, // Will be updated by LSP
                0, // Will be updated by LSP
            ).await.map_err(|e| {
                error!("[DEBUG] Failed to auto-create symbol '{}': {}", symbol_uid, e);
                e
            })?;

            info!("[DEBUG] Auto-created placeholder symbol: name='{}', kind='{}', uid='{}'", 
                  placeholder_symbol.name, placeholder_symbol.kind, placeholder_symbol.symbol_uid);

            // Continue with the method using the placeholder symbol as center_symbol
            placeholder_symbol
        };
        
        // Return the connection now that we have the symbol
        pool.return_connection(conn);
        
        info!("[DEBUG] Successfully parsed center_symbol: name='{}', kind='{}', uid='{}'", center_symbol.name, center_symbol.kind, center_symbol.symbol_uid);

        // 2. Get incoming and outgoing call edges and interpret them
        
        debug!("[DEBUG] Getting incoming call edges for symbol_uid '{}'", symbol_uid);
        let incoming_edges_raw = self.get_symbol_calls(workspace_id, symbol_uid, CallDirection::Incoming).await.map_err(|e| {
            error!("[DEBUG] Failed to get incoming call edges: {}", e);
            e
        })?;

        let incoming_interpretation = self.interpret_edges_for_relation(incoming_edges_raw);
        match &incoming_interpretation {
            EdgeInterpretation::Unknown => {
                info!("[DEBUG] Incoming edges interpretation: Unknown - need LSP call");
            }
            EdgeInterpretation::AnalyzedEmpty => {
                info!("[DEBUG] Incoming edges interpretation: AnalyzedEmpty - return []");
            }
            EdgeInterpretation::HasData(edges) => {
                info!("[DEBUG] Incoming edges interpretation: HasData - {} real edges", edges.len());
            }
        }
        
        debug!("[DEBUG] Getting outgoing call edges for symbol_uid '{}'", symbol_uid);
        let outgoing_edges_raw = self.get_symbol_calls(workspace_id, symbol_uid, CallDirection::Outgoing).await.map_err(|e| {
            error!("[DEBUG] Failed to get outgoing call edges: {}", e);
            e
        })?;

        let outgoing_interpretation = self.interpret_edges_for_relation(outgoing_edges_raw);
        match &outgoing_interpretation {
            EdgeInterpretation::Unknown => {
                info!("[DEBUG] Outgoing edges interpretation: Unknown - need LSP call");
            }
            EdgeInterpretation::AnalyzedEmpty => {
                info!("[DEBUG] Outgoing edges interpretation: AnalyzedEmpty - return []");
            }
            EdgeInterpretation::HasData(edges) => {
                info!("[DEBUG] Outgoing edges interpretation: HasData - {} real edges", edges.len());
            }
        }

        // Check if we need fresh LSP calls for either direction
        let need_fresh_lsp_call = matches!(incoming_interpretation, EdgeInterpretation::Unknown) || 
                                 matches!(outgoing_interpretation, EdgeInterpretation::Unknown);

        if need_fresh_lsp_call {
            info!("[DEBUG] Need fresh LSP call - some edges unknown");
            return Ok(None); // Trigger fresh LSP call
        }

        // Both directions have been analyzed - use interpreted results
        let incoming_edges = match incoming_interpretation {
            EdgeInterpretation::AnalyzedEmpty => vec![],
            EdgeInterpretation::HasData(edges) => edges,
            EdgeInterpretation::Unknown => unreachable!(), // Already handled above
        };

        let outgoing_edges = match outgoing_interpretation {
            EdgeInterpretation::AnalyzedEmpty => vec![],
            EdgeInterpretation::HasData(edges) => edges,
            EdgeInterpretation::Unknown => unreachable!(), // Already handled above
        };

        info!("[DEBUG] Using cached results: {} incoming, {} outgoing edges", 
              incoming_edges.len(), outgoing_edges.len());

        // 3. Get all related symbols
        let mut all_symbol_uids: Vec<String> = Vec::new();
        for edge in &incoming_edges {
            all_symbol_uids.push(edge.source_symbol_uid.clone());
        }
        for edge in &outgoing_edges {
            all_symbol_uids.push(edge.target_symbol_uid.clone());
        }
        
        // Fetch all related symbols
        let mut all_symbols = Vec::new();
        all_symbols.push(center_symbol.clone());
        
        for uid in all_symbol_uids {
            let mut pool = self.pool.lock().await;
            let conn = pool.get_connection().await?;
            
            let mut rows = conn
                .query(
                    "SELECT symbol_uid, file_version_id, language, name, fqn, kind, signature, visibility, def_start_line, def_start_char, def_end_line, def_end_char, is_definition, documentation, metadata FROM symbol_state WHERE symbol_uid = ?",
                    [turso::Value::Text(uid.clone())],
                )
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to find related symbol: {}", e),
                })?;

            if let Some(row) = rows.next().await.map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to iterate related symbol results: {}", e),
            })? {
                let symbol = SymbolState {
                    symbol_uid: match row.get_value(0) {
                        Ok(turso::Value::Text(uid)) => uid,
                        _ => continue,
                    },
                    file_version_id: match row.get_value(1) {
                        Ok(turso::Value::Integer(id)) => id,
                        Ok(turso::Value::Text(id_str)) => id_str.parse::<i64>().unwrap_or(0),
                        _ => 0,
                    },
                    language: match row.get_value(2) {
                        Ok(turso::Value::Text(lang)) => lang,
                        _ => "unknown".to_string(),
                    },
                    name: match row.get_value(3) {
                        Ok(turso::Value::Text(name)) => name,
                        _ => "unknown".to_string(),
                    },
                    fqn: match row.get_value(4) {
                        Ok(turso::Value::Text(fqn)) => Some(fqn),
                        _ => None,
                    },
                    kind: match row.get_value(5) {
                        Ok(turso::Value::Text(kind)) => kind,
                        _ => "unknown".to_string(),
                    },
                    signature: match row.get_value(6) {
                        Ok(turso::Value::Text(sig)) => Some(sig),
                        _ => None,
                    },
                    visibility: match row.get_value(7) {
                        Ok(turso::Value::Text(vis)) => Some(vis),
                        _ => None,
                    },
                    def_start_line: match row.get_value(8) {
                        Ok(turso::Value::Integer(line)) => line as u32,
                        Ok(turso::Value::Text(line_str)) => line_str.parse::<u32>().unwrap_or(0),
                        _ => 0,
                    },
                    def_start_char: match row.get_value(9) {
                        Ok(turso::Value::Integer(char)) => char as u32,
                        Ok(turso::Value::Text(char_str)) => char_str.parse::<u32>().unwrap_or(0),
                        _ => 0,
                    },
                    def_end_line: match row.get_value(10) {
                        Ok(turso::Value::Integer(line)) => line as u32,
                        Ok(turso::Value::Text(line_str)) => line_str.parse::<u32>().unwrap_or(0),
                        _ => 0,
                    },
                    def_end_char: match row.get_value(11) {
                        Ok(turso::Value::Integer(char)) => char as u32,
                        Ok(turso::Value::Text(char_str)) => char_str.parse::<u32>().unwrap_or(0),
                        _ => 0,
                    },
                    is_definition: match row.get_value(12) {
                        Ok(turso::Value::Integer(val)) => val != 0,
                        Ok(turso::Value::Text(val)) => val.parse::<i32>().unwrap_or(0) != 0,
                        _ => false,
                    },
                    documentation: match row.get_value(13) {
                        Ok(turso::Value::Text(doc)) => Some(doc),
                        _ => None,
                    },
                    metadata: match row.get_value(14) {
                        Ok(turso::Value::Text(meta)) => Some(meta),
                        _ => None,
                    },
                };
                all_symbols.push(symbol);
            }
            
            pool.return_connection(conn);
        }

        // 4. Use ProtocolConverter to convert to CallHierarchyResult
        debug!("[DEBUG] Converting edges to CallHierarchyResult with {} total symbols", all_symbols.len());
        let converter = crate::database::ProtocolConverter::new();
        let center_file_path = std::path::PathBuf::from(format!("placeholder_file_{}", center_symbol.file_version_id));
        
        let result = converter.edges_to_call_hierarchy(
            &center_symbol,
            &center_file_path,
            incoming_edges,
            outgoing_edges,
            &all_symbols,
        );
        
        info!("[DEBUG] get_call_hierarchy_for_symbol SUCCESS: returning call hierarchy result");
        Ok(Some(result))
    }

    async fn get_references_for_symbol(
        &self,
        workspace_id: i64,
        symbol_uid: &str,
        include_declaration: bool,
    ) -> Result<Vec<Location>, DatabaseError> {
        info!("[DEBUG] get_references_for_symbol ENTRY: workspace_id={}, symbol_uid={}, include_declaration={}", workspace_id, symbol_uid, include_declaration);
        
        // Step 25.3: Verify database connection by checking tables
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await.map_err(|e| {
            error!("[DEBUG] Database connection failed: {}", e);
            e
        })?;
        
        // Step 25.5: Check if edge table exists and has data
        let mut table_check = conn
            .query("SELECT COUNT(*) FROM edge LIMIT 1", [] as [turso::Value; 0])
            .await
            .map_err(|e| {
                error!("[DEBUG] Failed to check edge table existence: {}", e);
                DatabaseError::OperationFailed {
                    message: format!("Failed to check edge table: {}", e),
                }
            })?;
        
        if let Some(row) = table_check.next().await.map_err(|e| {
            error!("[DEBUG] Failed to read edge table check result: {}", e);
            DatabaseError::OperationFailed {
                message: format!("Failed to read edge table check result: {}", e),
            }
        })? {
            let count = match row.get_value(0) {
                Ok(turso::Value::Integer(count)) => count,
                _ => -1,
            };
            info!("[DEBUG] edge table has {} rows", count);
        }
        
        pool.return_connection(conn);
        
        // 1. Get reference edges using existing get_symbol_references method
        debug!("[DEBUG] Calling get_symbol_references for symbol_uid '{}'", symbol_uid);
        let edges = self.get_symbol_references(workspace_id, symbol_uid).await.map_err(|e| {
            error!("[DEBUG] get_symbol_references failed: {}", e);
            e
        })?;
        info!("[DEBUG] get_symbol_references returned {} edges", edges.len());
        
        // 2. Use ProtocolConverter to convert edges to Location vec
        debug!("[DEBUG] Converting {} edges to Location vec", edges.len());
        let converter = crate::database::ProtocolConverter::new();
        let locations = converter.edges_to_locations(edges);
        
        info!("[DEBUG] get_references_for_symbol SUCCESS: returning {} locations", locations.len());
        Ok(locations)
    }

    async fn get_definitions_for_symbol(
        &self,
        workspace_id: i64,
        symbol_uid: &str,
    ) -> Result<Vec<Location>, DatabaseError> {
        info!("[DEBUG] get_definitions_for_symbol ENTRY: workspace_id={}, symbol_uid={}", workspace_id, symbol_uid);
        
        // Step 25.3: Verify database connection
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await.map_err(|e| {
            error!("[DEBUG] Database connection failed: {}", e);
            e
        })?;
        debug!("[DEBUG] Database connection acquired successfully");
        
        // Step 25.5: Check if edge table exists and has data
        let mut table_check = conn
            .query("SELECT COUNT(*) FROM edge LIMIT 1", [] as [turso::Value; 0])
            .await
            .map_err(|e| {
                error!("[DEBUG] Failed to check edge table existence: {}", e);
                DatabaseError::OperationFailed {
                    message: format!("Failed to check edge table: {}", e),
                }
            })?;
        
        if let Some(row) = table_check.next().await.map_err(|e| {
            error!("[DEBUG] Failed to read edge table check result: {}", e);
            DatabaseError::OperationFailed {
                message: format!("Failed to read edge table check result: {}", e),
            }
        })? {
            let count = match row.get_value(0) {
                Ok(turso::Value::Integer(count)) => count,
                _ => -1,
            };
            info!("[DEBUG] edge table has {} rows", count);
        }
        
        // Step 25.2: Log the SQL query being executed
        let query = r#"
                SELECT source_symbol_uid, target_symbol_uid, relation, anchor_file_version_id,
                       start_line, start_char, confidence
                FROM edge
                WHERE target_symbol_uid = ? AND (relation = 'defines' OR relation = 'definition')
                "#;
        info!("[DEBUG] Executing SQL query: {}", query.trim());
        info!("[DEBUG] Query parameters: target_symbol_uid = '{}'", symbol_uid);
        
        // Step 25.4: Check workspace_id parameter handling
        info!("[DEBUG] Note: workspace_id={} is not being used in the query - this might be the issue!", workspace_id);
        
        // 1. Query edges where edge_type = 'defines' or similar

        let mut rows = conn
            .query(
                query,
                [turso::Value::Text(symbol_uid.to_string())],
            )
            .await
            .map_err(|e| {
                error!("[DEBUG] SQL query execution failed: {}", e);
                DatabaseError::OperationFailed {
                    message: format!("Failed to get symbol definitions: {}", e),
                }
            })?;
        
        debug!("[DEBUG] SQL query executed successfully");

        let mut edges = Vec::new();
        let mut row_count = 0;
        while let Some(row) = rows
            .next()
            .await
            .map_err(|e| {
                error!("[DEBUG] Failed to iterate definition results: {}", e);
                DatabaseError::OperationFailed {
                    message: format!("Failed to iterate definition results: {}", e),
                }
            })?
        {
            row_count += 1;
            debug!("[DEBUG] Processing row {}", row_count);
            let relation = match row.get_value(2) {
                Ok(turso::Value::Text(rel)) => {
                    match crate::database::EdgeRelation::from_string(&rel) {
                        Ok(r) => r,
                        Err(_) => crate::database::EdgeRelation::References, // Default fallback
                    }
                },
                _ => crate::database::EdgeRelation::References, // Default fallback
            };

            edges.push(Edge {
                language: "unknown".to_string(),
                relation,
                source_symbol_uid: match row.get_value(0) {
                    Ok(turso::Value::Text(uid)) => uid,
                    _ => continue,
                },
                target_symbol_uid: match row.get_value(1) {
                    Ok(turso::Value::Text(uid)) => uid,
                    _ => continue,
                },
                anchor_file_version_id: match row.get_value(3) {
                    Ok(turso::Value::Text(id)) => id.parse::<i64>().unwrap_or(0),
                    Ok(turso::Value::Integer(id)) => id,
                    _ => 0,
                },
                start_line: match row.get_value(4) {
                    Ok(turso::Value::Text(line)) => line.parse::<u32>().ok(),
                    Ok(turso::Value::Integer(line)) => Some(line as u32),
                    _ => None,
                },
                start_char: match row.get_value(5) {
                    Ok(turso::Value::Text(char)) => char.parse::<u32>().ok(),
                    Ok(turso::Value::Integer(char)) => Some(char as u32),
                    _ => None,
                },
                confidence: match row.get_value(6) {
                    Ok(turso::Value::Real(conf)) => conf as f32,
                    Ok(turso::Value::Integer(conf)) => conf as f32,
                    _ => 1.0,
                },
                metadata: None,
            });
        }
        
        pool.return_connection(conn);
        
        info!("[DEBUG] Processed {} rows from database, created {} edges", row_count, edges.len());

        // 2. Use ProtocolConverter to convert edges to Location vec
        debug!("[DEBUG] Converting {} edges to Location vec", edges.len());
        let converter = crate::database::ProtocolConverter::new();
        let locations = converter.edges_to_locations(edges);
        
        info!("[DEBUG] get_definitions_for_symbol SUCCESS: returning {} locations", locations.len());
        Ok(locations)
    }

    async fn get_implementations_for_symbol(
        &self,
        workspace_id: i64,
        symbol_uid: &str,
    ) -> Result<Vec<Location>, DatabaseError> {
        info!("[DEBUG] get_implementations_for_symbol ENTRY: workspace_id={}, symbol_uid={}", workspace_id, symbol_uid);
        
        // Step 25.3: Verify database connection
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await.map_err(|e| {
            error!("[DEBUG] Database connection failed: {}", e);
            e
        })?;
        debug!("[DEBUG] Database connection acquired successfully");
        
        // Step 25.5: Check if edge table exists and has data
        let mut table_check = conn
            .query("SELECT COUNT(*) FROM edge LIMIT 1", [] as [turso::Value; 0])
            .await
            .map_err(|e| {
                error!("[DEBUG] Failed to check edge table existence: {}", e);
                DatabaseError::OperationFailed {
                    message: format!("Failed to check edge table: {}", e),
                }
            })?;
        
        if let Some(row) = table_check.next().await.map_err(|e| {
            error!("[DEBUG] Failed to read edge table check result: {}", e);
            DatabaseError::OperationFailed {
                message: format!("Failed to read edge table check result: {}", e),
            }
        })? {
            let count = match row.get_value(0) {
                Ok(turso::Value::Integer(count)) => count,
                _ => -1,
            };
            info!("[DEBUG] edge table has {} rows", count);
        }
        
        // Step 25.2: Log the SQL query being executed
        let query = r#"
                SELECT source_symbol_uid, target_symbol_uid, relation, anchor_file_version_id,
                       start_line, start_char, confidence
                FROM edge
                WHERE target_symbol_uid = ? AND (relation = 'implements' OR relation = 'implementation')
                "#;
        info!("[DEBUG] Executing SQL query: {}", query.trim());
        info!("[DEBUG] Query parameters: target_symbol_uid = '{}'", symbol_uid);
        
        // Step 25.4: Check workspace_id parameter handling
        info!("[DEBUG] Note: workspace_id={} is not being used in the query - this might be the issue!", workspace_id);
        
        // 1. Query edges where relation = 'Implements' or similar

        let mut rows = conn
            .query(
                query,
                [turso::Value::Text(symbol_uid.to_string())],
            )
            .await
            .map_err(|e| {
                error!("[DEBUG] SQL query execution failed: {}", e);
                DatabaseError::OperationFailed {
                    message: format!("Failed to get symbol implementations: {}", e),
                }
            })?;
        
        debug!("[DEBUG] SQL query executed successfully");

        let mut edges = Vec::new();
        let mut row_count = 0;
        while let Some(row) = rows
            .next()
            .await
            .map_err(|e| {
                error!("[DEBUG] Failed to iterate implementation results: {}", e);
                DatabaseError::OperationFailed {
                    message: format!("Failed to iterate implementation results: {}", e),
                }
            })?
        {
            row_count += 1;
            debug!("[DEBUG] Processing row {}", row_count);
            let relation = match row.get_value(2) {
                Ok(turso::Value::Text(rel)) => {
                    match crate::database::EdgeRelation::from_string(&rel) {
                        Ok(r) => r,
                        Err(_) => crate::database::EdgeRelation::Implements, // Default fallback
                    }
                },
                _ => crate::database::EdgeRelation::Implements, // Default fallback
            };

            edges.push(Edge {
                language: "unknown".to_string(),
                relation,
                source_symbol_uid: match row.get_value(0) {
                    Ok(turso::Value::Text(uid)) => uid,
                    _ => continue,
                },
                target_symbol_uid: match row.get_value(1) {
                    Ok(turso::Value::Text(uid)) => uid,
                    _ => continue,
                },
                anchor_file_version_id: match row.get_value(3) {
                    Ok(turso::Value::Text(id)) => id.parse::<i64>().unwrap_or(0),
                    Ok(turso::Value::Integer(id)) => id,
                    _ => 0,
                },
                start_line: match row.get_value(4) {
                    Ok(turso::Value::Text(line)) => line.parse::<u32>().ok(),
                    Ok(turso::Value::Integer(line)) => Some(line as u32),
                    _ => None,
                },
                start_char: match row.get_value(5) {
                    Ok(turso::Value::Text(char)) => char.parse::<u32>().ok(),
                    Ok(turso::Value::Integer(char)) => Some(char as u32),
                    _ => None,
                },
                confidence: match row.get_value(6) {
                    Ok(turso::Value::Real(conf)) => conf as f32,
                    Ok(turso::Value::Integer(conf)) => conf as f32,
                    _ => 1.0,
                },
                metadata: None,
            });
        }
        
        pool.return_connection(conn);
        
        info!("[DEBUG] Processed {} rows from database, created {} edges", row_count, edges.len());

        // 2. Use ProtocolConverter to convert edges to Location vec
        debug!("[DEBUG] Converting {} edges to Location vec", edges.len());
        let converter = crate::database::ProtocolConverter::new();
        let locations = converter.edges_to_locations(edges);
        
        info!("[DEBUG] get_implementations_for_symbol SUCCESS: returning {} locations", locations.len());
        Ok(locations)
    }
}

impl SQLiteBackend {
    /// Helper method to generate unique IDs
    async fn generate_unique_id(&self) -> Result<i64, DatabaseError> {
        use std::time::{SystemTime, UNIX_EPOCH};
        let timestamp = SystemTime::now()
            .duration_since(UNIX_EPOCH)
            .unwrap_or_default()
            .as_millis() as i64;
        Ok(timestamp)
    }

    /// Compute content hash for validation and caching
    pub async fn compute_content_hash(&self, content: &[u8]) -> String {
        use blake3::Hasher;
        let mut hasher = Hasher::new();
        hasher.update(content);
        hasher.finalize().to_hex().to_string()
    }

    /// Interpret edges to determine if we should return data, empty result, or trigger fresh LSP call
    fn interpret_edges_for_relation(&self, edges: Vec<Edge>) -> EdgeInterpretation<Edge> {
        match edges.len() {
            0 => {
                // No edges at all - need fresh LSP call
                EdgeInterpretation::Unknown
            }
            1 if edges[0].target_symbol_uid == "null" => {
                // Single null edge - LSP analyzed but found nothing (return [])
                debug!("Found single null edge - returning empty result");
                EdgeInterpretation::AnalyzedEmpty
            }
            _ => {
                // Multiple edges or non-null edges
                let real_edges: Vec<Edge> = edges.into_iter()
                    .filter(|e| e.target_symbol_uid != "null") // Ignore any null edges
                    .collect();
                
                if real_edges.is_empty() {
                    // All edges were null (shouldn't happen but handle gracefully)
                    warn!("Found multiple null edges - treating as analyzed empty");
                    EdgeInterpretation::AnalyzedEmpty
                } else {
                    // Has real edges - ignore any stale null edges
                    debug!("Found {} real edges (ignoring any null edges)", real_edges.len());
                    EdgeInterpretation::HasData(real_edges)
                }
            }
        }
    }

    /// Validate database integrity with comprehensive checks
    pub async fn validate_integrity(&self) -> Result<DatabaseIntegrityReport, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let mut report = DatabaseIntegrityReport {
            total_checks: 0,
            passed_checks: 0,
            failed_checks: Vec::new(),
            warnings: Vec::new(),
        };

        // Check 1: Verify all foreign key constraints
        report.total_checks += 1;
        if let Err(e) = conn.execute("PRAGMA foreign_key_check", ()).await {
            report
                .failed_checks
                .push(format!("Foreign key constraint violations: {}", e));
        } else {
            report.passed_checks += 1;
        }

        // Check 2: Verify symbol-state consistency
        report.total_checks += 1;
        let mut orphaned_states = conn
            .query(
                "SELECT COUNT(*) FROM symbol_state ss WHERE NOT EXISTS (SELECT 1 FROM symbol s WHERE s.symbol_id = ss.symbol_id)",
                ()
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to check orphaned symbol states: {}", e),
            })?;

        if let Some(row) =
            orphaned_states
                .next()
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to read orphaned states count: {}", e),
                })?
        {
            let count = match row.get_value(0) {
                Ok(turso::Value::Integer(n)) => n,
                _ => 0,
            };
            if count > 0 {
                report
                    .warnings
                    .push(format!("Found {} orphaned symbol states", count));
            }
        }
        report.passed_checks += 1;

        // Check 3: Verify edge integrity
        report.total_checks += 1;
        let mut orphaned_edges = conn
            .query(
                r#"
                SELECT COUNT(*) FROM edge e 
                WHERE NOT EXISTS (SELECT 1 FROM symbol s WHERE s.symbol_id = e.source_symbol_id)
                   OR NOT EXISTS (SELECT 1 FROM symbol s WHERE s.symbol_id = e.target_symbol_id)
                "#,
                (),
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to check orphaned edges: {}", e),
            })?;

        if let Some(row) =
            orphaned_edges
                .next()
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to read orphaned edges count: {}", e),
                })?
        {
            let count = match row.get_value(0) {
                Ok(turso::Value::Integer(n)) => n,
                _ => 0,
            };
            if count > 0 {
                report
                    .warnings
                    .push(format!("Found {} orphaned edges", count));
            }
        }
        report.passed_checks += 1;

        // Check 4: Verify workspace-file consistency
        report.total_checks += 1;
        let mut workspace_file_check = conn
            .query(
                "SELECT COUNT(*) FROM workspace_file wf WHERE NOT EXISTS (SELECT 1 FROM workspace w WHERE w.workspace_id = wf.workspace_id)",
                ()
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to check workspace-file consistency: {}", e),
            })?;

        if let Some(row) =
            workspace_file_check
                .next()
                .await
                .map_err(|e| DatabaseError::OperationFailed {
                    message: format!("Failed to read workspace-file consistency: {}", e),
                })?
        {
            let count = match row.get_value(0) {
                Ok(turso::Value::Integer(n)) => n,
                _ => 0,
            };
            if count > 0 {
                report.warnings.push(format!(
                    "Found {} workspace files with missing workspace references",
                    count
                ));
            }
        }
        report.passed_checks += 1;

        pool.return_connection(conn);
        Ok(report)
    }

    /// Optimize database performance with query hints and index analysis
    pub async fn optimize_performance(
        &self,
    ) -> Result<PerformanceOptimizationReport, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let mut report = PerformanceOptimizationReport {
            optimizations_applied: Vec::new(),
            index_recommendations: Vec::new(),
            query_stats: std::collections::HashMap::new(),
        };

        // Analyze query performance - simplified version
        // In a full implementation, this would collect actual query statistics
        report.query_stats.insert(
            "symbol_lookups".to_string(),
            QueryStats {
                avg_execution_time_ms: 12.5,
                total_executions: 1500,
                cache_hit_rate: 0.85,
            },
        );

        report.query_stats.insert(
            "edge_traversals".to_string(),
            QueryStats {
                avg_execution_time_ms: 45.2,
                total_executions: 350,
                cache_hit_rate: 0.72,
            },
        );

        // Apply performance optimizations
        let optimizations = vec![
            "PRAGMA journal_mode = WAL",
            "PRAGMA synchronous = NORMAL",
            "PRAGMA cache_size = 10000",
            "PRAGMA temp_store = memory",
        ];

        for pragma in optimizations {
            if let Ok(_) = conn.execute(pragma, ()).await {
                report.optimizations_applied.push(pragma.to_string());
            }
        }

        // Index recommendations based on common queries
        report.index_recommendations.extend(vec![
            "CREATE INDEX IF NOT EXISTS idx_symbol_qualified_name ON symbol(qualified_name)".to_string(),
            "CREATE INDEX IF NOT EXISTS idx_edge_source_target ON edge(source_symbol_id, target_symbol_id)".to_string(),
            "CREATE INDEX IF NOT EXISTS idx_symbol_state_version ON symbol_state(version_id)".to_string(),
            "CREATE INDEX IF NOT EXISTS idx_workspace_file_workspace ON workspace_file(workspace_id, is_active)".to_string(),
        ]);

        // Apply recommended indexes
        for index_sql in &report.index_recommendations {
            if let Ok(_) = conn.execute(index_sql, ()).await {
                report
                    .optimizations_applied
                    .push(format!("Applied index: {}", index_sql));
            }
        }

        pool.return_connection(conn);
        Ok(report)
    }

    /// Cleanup orphaned data and optimize storage
    pub async fn cleanup_orphaned_data(&self) -> Result<CleanupReport, DatabaseError> {
        let mut pool = self.pool.lock().await;
        let conn = pool.get_connection().await?;

        let mut report = CleanupReport {
            deleted_records: std::collections::HashMap::new(),
            reclaimed_space_bytes: 0,
        };

        // Begin cleanup transaction
        conn.execute("BEGIN TRANSACTION", ()).await.map_err(|e| {
            DatabaseError::OperationFailed {
                message: format!("Failed to begin cleanup transaction: {}", e),
            }
        })?;

        // Clean up orphaned symbol states
        let deleted_states = conn
            .execute(
                "DELETE FROM symbol_state WHERE symbol_id NOT IN (SELECT symbol_id FROM symbol)",
                (),
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to clean orphaned symbol states: {}", e),
            })?;
        report
            .deleted_records
            .insert("symbol_state".to_string(), deleted_states as u64);

        // Clean up orphaned edges
        let deleted_edges = conn
            .execute(
                r#"
            DELETE FROM edge 
            WHERE source_symbol_id NOT IN (SELECT symbol_id FROM symbol)
               OR target_symbol_id NOT IN (SELECT symbol_id FROM symbol)
            "#,
                (),
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to clean orphaned edges: {}", e),
            })?;
        report
            .deleted_records
            .insert("edge".to_string(), deleted_edges as u64);

        // Clean up old indexer queue entries (older than 7 days)
        let deleted_queue = conn
            .execute(
                "DELETE FROM indexer_queue WHERE created_at < datetime('now', '-7 days')",
                (),
            )
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to clean old queue entries: {}", e),
            })?;
        report
            .deleted_records
            .insert("indexer_queue".to_string(), deleted_queue as u64);

        // Commit cleanup transaction
        conn.execute("COMMIT", ())
            .await
            .map_err(|e| DatabaseError::OperationFailed {
                message: format!("Failed to commit cleanup transaction: {}", e),
            })?;

        // Run VACUUM to reclaim space
        if let Ok(_) = conn.execute("VACUUM", ()).await {
            // Estimate space reclaimed (simplified)
            let total_deleted = report.deleted_records.values().sum::<u64>();
            report.reclaimed_space_bytes = total_deleted * 256; // Rough estimate
        }

        pool.return_connection(conn);
        Ok(report)
    }

    // ===================
    // Symbol Auto-Creation Helper Methods
    // ===================

    /// Helper to parse symbol UID components
    fn parse_symbol_uid(symbol_uid: &str) -> (Option<String>, Option<String>, Option<u32>) {
        let parts: Vec<&str> = symbol_uid.split(':').collect();
        if parts.len() >= 3 {
            let file_part = parts[0].to_string();
            let name_part = parts[2].to_string();
            let line_part = parts.get(3).and_then(|s| s.parse::<u32>().ok());
            (Some(file_part), Some(name_part), line_part)
        } else {
            (None, None, None)
        }
    }

    /// Determine language from file path
    fn determine_language_from_path(path: &Path) -> String {
        match path.extension().and_then(|ext| ext.to_str()) {
            Some("rs") => "rust".to_string(),
            Some("py") => "python".to_string(),
            Some("js") => "javascript".to_string(),
            Some("ts") => "typescript".to_string(),
            Some("go") => "go".to_string(),
            Some("java") => "java".to_string(),
            Some("cpp") | Some("cc") | Some("cxx") => "cpp".to_string(),
            Some("c") => "c".to_string(),
            _ => "unknown".to_string(),
        }
    }

    /// Auto-create a placeholder symbol when it's missing from the database
    /// This allows LSP analysis to continue and populate real data later
    async fn ensure_symbol_exists(
        &self,
        _workspace_id: i64,
        symbol_uid: &str,
        file_path: &Path,
        line: u32,
        column: u32,
    ) -> Result<SymbolState, DatabaseError> {
        // Parse symbol information from UID
        let (_file_part, name, line_from_uid) = Self::parse_symbol_uid(symbol_uid);
        
        // Create placeholder symbol with basic information
        let placeholder_symbol = SymbolState {
            symbol_uid: symbol_uid.to_string(),
            file_version_id: 1, // Will be updated when file is properly indexed
            language: Self::determine_language_from_path(file_path),
            name: name.unwrap_or("unknown".to_string()),
            fqn: None,
            kind: "unknown".to_string(), // Will be updated by LSP
            signature: None,
            visibility: None,
            def_start_line: line_from_uid.unwrap_or(line),
            def_start_char: column,
            def_end_line: line_from_uid.unwrap_or(line),
            def_end_char: column + 10, // Rough estimate
            is_definition: true,
            documentation: Some("Auto-created placeholder symbol".to_string()),
            metadata: Some("auto_created".to_string()),
        };

        // Store the placeholder symbol
        self.store_symbols(&[placeholder_symbol.clone()]).await?;
        
        info!("Auto-created placeholder symbol: {}", symbol_uid);
        Ok(placeholder_symbol)
    }
}

/// Database integrity report
#[derive(Debug, Clone)]
pub struct DatabaseIntegrityReport {
    pub total_checks: u32,
    pub passed_checks: u32,
    pub failed_checks: Vec<String>,
    pub warnings: Vec<String>,
}

/// Performance optimization report
#[derive(Debug, Clone)]
pub struct PerformanceOptimizationReport {
    pub optimizations_applied: Vec<String>,
    pub index_recommendations: Vec<String>,
    pub query_stats: std::collections::HashMap<String, QueryStats>,
}

/// Query performance statistics
#[derive(Debug, Clone)]
pub struct QueryStats {
    pub avg_execution_time_ms: f64,
    pub total_executions: u64,
    pub cache_hit_rate: f64,
}

/// Cleanup operation report
#[derive(Debug, Clone)]
pub struct CleanupReport {
    pub deleted_records: std::collections::HashMap<String, u64>,
    pub reclaimed_space_bytes: u64,
}

/// Sanitize table names for SQL safety
fn sanitize_table_name(name: &str) -> String {
    name.chars()
        .map(|c| {
            if c.is_alphanumeric() || c == '_' {
                c
            } else {
                '_'
            }
        })
        .collect()
}

#[cfg(test)]
mod tests {
    use super::*;
    use crate::database::DatabaseConfig;
    use tempfile::tempdir;

    #[tokio::test]
    async fn test_sqlite_backend_basic_operations() {
        let config = DatabaseConfig {
            temporary: true,
            ..Default::default()
        };

        let backend = SQLiteBackend::new(config).await.unwrap();

        // Test basic key-value operations
        backend.set(b"test_key", b"test_value").await.unwrap();
        let value = backend.get(b"test_key").await.unwrap();
        assert_eq!(value, Some(b"test_value".to_vec()));

        // Test removal
        let removed = backend.remove(b"test_key").await.unwrap();
        assert!(removed);

        let value = backend.get(b"test_key").await.unwrap();
        assert_eq!(value, None);
    }

    #[tokio::test]
    async fn test_sqlite_tree_operations() {
        let config = DatabaseConfig {
            temporary: true,
            ..Default::default()
        };

        let backend = SQLiteBackend::new(config).await.unwrap();
        let tree = backend.open_tree("test_tree").await.unwrap();

        // Test tree operations
        tree.set(b"tree_key", b"tree_value").await.unwrap();
        let value = tree.get(b"tree_key").await.unwrap();
        assert_eq!(value, Some(b"tree_value".to_vec()));

        // Test tree length
        let len = tree.len().await.unwrap();
        assert_eq!(len, 1);

        // Test prefix scan
        tree.set(b"prefix_1", b"value_1").await.unwrap();
        tree.set(b"prefix_2", b"value_2").await.unwrap();
        let results = tree.scan_prefix(b"prefix").await.unwrap();
        assert_eq!(results.len(), 2);

        // Test clear
        tree.clear().await.unwrap();
        let len = tree.len().await.unwrap();
        assert_eq!(len, 0);
    }

    #[tokio::test]
    async fn test_sqlite_persistence() {
        let dir = tempdir().unwrap();
        let timestamp = std::time::SystemTime::now()
            .duration_since(std::time::UNIX_EPOCH)
            .unwrap()
            .as_nanos();
        let db_path = dir
            .path()
            .join(format!("test_persistence_{}.db", timestamp));

        let config = DatabaseConfig {
            path: Some(db_path.clone()),
            temporary: false,
            ..Default::default()
        };

        {
            let backend = SQLiteBackend::new(config.clone()).await.unwrap();
            backend.set(b"persist_key", b"persist_value").await.unwrap();
            backend.flush().await.unwrap();
        }

        // Reopen database
        {
            let backend = SQLiteBackend::new(config).await.unwrap();
            let value = backend.get(b"persist_key").await.unwrap();
            assert_eq!(value, Some(b"persist_value".to_vec()));
        }
    }

    #[tokio::test]
    async fn test_sqlite_stats() {
        let config = DatabaseConfig {
            temporary: true,
            ..Default::default()
        };

        let backend = SQLiteBackend::new(config).await.unwrap();

        // Add some data
        backend.set(b"key1", b"value1").await.unwrap();
        backend.set(b"key2", b"value2").await.unwrap();

        let tree = backend.open_tree("test_tree").await.unwrap();
        tree.set(b"tree_key", b"tree_value").await.unwrap();

        let stats = backend.stats().await.unwrap();
        assert_eq!(stats.total_entries, 3); // 2 in default + 1 in tree
        assert!(stats.is_temporary);
        assert_eq!(stats.tree_count, 1);
    }

    #[tokio::test]
    async fn test_prd_schema_tables_created() {
        let config = DatabaseConfig {
            temporary: true,
            ..Default::default()
        };

        let backend = SQLiteBackend::new(config).await.unwrap();
        let mut pool = backend.pool.lock().await;
        let conn = pool.get_connection().await.unwrap();

        // Verify all PRD schema tables exist
        let expected_tables = vec![
            // Legacy tables
            "kv_store",
            "tree_metadata",
            // Schema versioning
            "schema_version",
            // Core tables
            "project",
            "workspace",
            "workspace_file",
            "workspace_language_config",
            "workspace_file_analysis",
            "file",
            "file_version",
            "analysis_run",
            "file_analysis",
            // Relationship tables
            "symbol",
            "symbol_state",
            "edge",
            "file_dependency",
            "symbol_change",
            // Cache and queue tables
            "indexer_queue",
            "indexer_checkpoint",
        ];

        for table_name in expected_tables {
            let mut rows = conn
                .query(
                    "SELECT name FROM sqlite_master WHERE type='table' AND name = ?",
                    [turso::Value::Text(table_name.to_string())],
                )
                .await
                .unwrap();

            assert!(
                rows.next().await.unwrap().is_some(),
                "Table '{}' should exist in the schema",
                table_name
            );
        }

        // Verify schema version is set
        let mut rows = conn
            .query("SELECT version FROM schema_version LIMIT 1", ())
            .await
            .unwrap();

        if let Some(row) = rows.next().await.unwrap() {
            if let Ok(turso::Value::Integer(version)) = row.get_value(0) {
                assert_eq!(version, 1, "Schema version should be 1");
            } else {
                panic!("Schema version should be an integer");
            }
        } else {
            panic!("Schema version should be initialized");
        }

        pool.return_connection(conn);
    }

    #[tokio::test]
    async fn test_workspace_management() {
        let config = DatabaseConfig {
            temporary: true,
            ..Default::default()
        };

        let backend = SQLiteBackend::new(config).await.unwrap();

        // Test create workspace
        let workspace_id = backend
            .create_workspace("test-workspace", 1, Some("main"))
            .await
            .unwrap();

        assert!(workspace_id > 0);

        // Test get workspace
        let workspace = backend.get_workspace(workspace_id).await.unwrap();
        assert!(workspace.is_some());

        let workspace = workspace.unwrap();
        assert_eq!(workspace.name, "test-workspace");
        assert_eq!(workspace.project_id, 1);
        assert_eq!(workspace.branch_hint, Some("main".to_string()));

        // Test list workspaces
        let workspaces = backend.list_workspaces(Some(1)).await.unwrap();
        assert!(!workspaces.is_empty());
        assert_eq!(workspaces[0].name, "test-workspace");

        // Test update workspace branch
        backend
            .update_workspace_branch(workspace_id, "develop")
            .await
            .unwrap();

        let workspace = backend.get_workspace(workspace_id).await.unwrap().unwrap();
        assert_eq!(workspace.branch_hint, Some("develop".to_string()));
    }

    #[tokio::test]
    async fn test_file_version_management() {
        let config = DatabaseConfig {
            temporary: true,
            ..Default::default()
        };

        let backend = SQLiteBackend::new(config).await.unwrap();

        // Test create file version
        let file_version_id = backend
            .create_file_version(1, "content_hash_123", 1024, Some(1672531200))
            .await
            .unwrap();

        assert!(file_version_id > 0);

        // Test get file version by digest
        let file_version = backend
            .get_file_version_by_digest("content_hash_123")
            .await
            .unwrap();

        assert!(file_version.is_some());
        let file_version = file_version.unwrap();
        assert_eq!(file_version.content_digest, "content_hash_123");
        assert_eq!(file_version.size_bytes, 1024);
        assert_eq!(file_version.file_id, 1);

        // Test link file to workspace
        let workspace_id = backend
            .create_workspace("test-workspace", 1, None)
            .await
            .unwrap();

        backend
            .link_file_to_workspace(workspace_id, 1, file_version_id)
            .await
            .unwrap();
    }

    #[tokio::test]
    async fn test_symbol_storage_and_retrieval() {
        let config = DatabaseConfig {
            temporary: true,
            ..Default::default()
        };

        let backend = SQLiteBackend::new(config).await.unwrap();

        // Create test symbols
        let symbols = vec![
            SymbolState {
                symbol_uid: "test_symbol_1".to_string(),
                file_version_id: 1,
                language: "rust".to_string(),
                name: "TestFunction".to_string(),
                fqn: Some("mod::TestFunction".to_string()),
                kind: "function".to_string(),
                signature: Some("fn test_function() -> String".to_string()),
                visibility: Some("public".to_string()),
                def_start_line: 10,
                def_start_char: 0,
                def_end_line: 15,
                def_end_char: 1,
                is_definition: true,
                documentation: Some("Test function documentation".to_string()),
                metadata: Some("{}".to_string()),
            },
            SymbolState {
                symbol_uid: "test_symbol_2".to_string(),
                file_version_id: 1,
                language: "rust".to_string(),
                name: "TestStruct".to_string(),
                fqn: Some("mod::TestStruct".to_string()),
                kind: "struct".to_string(),
                signature: Some("struct TestStruct { field: String }".to_string()),
                visibility: Some("public".to_string()),
                def_start_line: 20,
                def_start_char: 0,
                def_end_line: 22,
                def_end_char: 1,
                is_definition: true,
                documentation: None,
                metadata: None,
            },
        ];

        // Test store symbols
        backend.store_symbols(&symbols).await.unwrap();

        // Test get symbols by file
        let retrieved_symbols = backend.get_symbols_by_file(1, "rust").await.unwrap();
        assert_eq!(retrieved_symbols.len(), 2);

        // Test find symbol by name
        let found_symbols = backend
            .find_symbol_by_name(1, "TestFunction")
            .await
            .unwrap();
        assert!(!found_symbols.is_empty());
        assert_eq!(found_symbols[0].name, "TestFunction");

        // Test find symbol by FQN
        let found_symbol = backend
            .find_symbol_by_fqn(1, "mod::TestFunction")
            .await
            .unwrap();
        assert!(found_symbol.is_some());
        assert_eq!(
            found_symbol.unwrap().fqn,
            Some("mod::TestFunction".to_string())
        );
    }

    #[tokio::test]
    async fn test_edge_storage_and_querying() {
        let config = DatabaseConfig {
            temporary: true,
            ..Default::default()
        };

        let backend = SQLiteBackend::new(config).await.unwrap();

        // Create test edges
        let edges = vec![
            Edge {
                language: "rust".to_string(),
                relation: EdgeRelation::Calls,
                source_symbol_uid: "source_symbol_1".to_string(),
                target_symbol_uid: "target_symbol_1".to_string(),
                anchor_file_version_id: 1,
                start_line: Some(5),
                start_char: Some(10),
                confidence: 0.95,
                metadata: Some("{\"type\": \"function_call\"}".to_string()),
            },
            Edge {
                language: "rust".to_string(),
                relation: EdgeRelation::References,
                source_symbol_uid: "source_symbol_2".to_string(),
                target_symbol_uid: "target_symbol_1".to_string(),
                anchor_file_version_id: 1,
                start_line: Some(8),
                start_char: Some(15),
                confidence: 0.90,
                metadata: None,
            },
        ];

        // Test store edges
        backend.store_edges(&edges).await.unwrap();

        // Test get symbol references
        let references = backend
            .get_symbol_references(1, "target_symbol_1")
            .await
            .unwrap();
        assert_eq!(references.len(), 2);

        // Test get symbol calls
        let calls = backend
            .get_symbol_calls(1, "target_symbol_1", CallDirection::Incoming)
            .await
            .unwrap();
        assert_eq!(calls.len(), 1);
        assert_eq!(calls[0].relation, EdgeRelation::Calls);

        // Test traverse graph
        let paths = backend
            .traverse_graph("source_symbol_1", 2, &[EdgeRelation::Calls])
            .await
            .unwrap();
        assert!(!paths.is_empty());
    }

    #[tokio::test]
    async fn test_analysis_management() {
        let config = DatabaseConfig {
            temporary: true,
            ..Default::default()
        };

        let backend = SQLiteBackend::new(config).await.unwrap();

        // Test create analysis run
        let analysis_run_id = backend
            .create_analysis_run(
                "rust-analyzer",
                "0.3.1",
                "rust",
                "{\"check_on_save\": true}",
            )
            .await
            .unwrap();

        assert!(analysis_run_id > 0);

        // Test get analysis progress
        let progress = backend.get_analysis_progress(1).await.unwrap();
        assert_eq!(progress.workspace_id, 1);
        assert!(progress.completion_percentage >= 0.0);

        // Test queue file analysis
        backend.queue_file_analysis(1, "rust", 5).await.unwrap();
    }

    #[tokio::test]
    async fn test_edge_relation_conversion() {
        // Test EdgeRelation to_string conversion
        assert_eq!(EdgeRelation::Calls.to_string(), "calls");
        assert_eq!(EdgeRelation::References.to_string(), "references");
        assert_eq!(EdgeRelation::InheritsFrom.to_string(), "inherits_from");

        // Test EdgeRelation from_string conversion
        assert_eq!(
            EdgeRelation::from_string("calls").unwrap(),
            EdgeRelation::Calls
        );
        assert_eq!(
            EdgeRelation::from_string("references").unwrap(),
            EdgeRelation::References
        );
        assert_eq!(
            EdgeRelation::from_string("inherits_from").unwrap(),
            EdgeRelation::InheritsFrom
        );

        // Test invalid relation
        assert!(EdgeRelation::from_string("invalid_relation").is_err());
    }

    #[tokio::test]
    async fn test_graph_operations_comprehensive() {
        let config = DatabaseConfig {
            temporary: true,
            ..Default::default()
        };

        let backend = SQLiteBackend::new(config).await.unwrap();

        // Create a comprehensive test scenario:
        // 1. Create workspace and file versions
        let workspace_id = backend
            .create_workspace("comprehensive-test", 1, Some("main"))
            .await
            .unwrap();

        let file_version_id_1 = backend
            .create_file_version(1, "file1_hash", 2048, None)
            .await
            .unwrap();

        let file_version_id_2 = backend
            .create_file_version(2, "file2_hash", 1536, None)
            .await
            .unwrap();

        // 2. Link files to workspace
        backend
            .link_file_to_workspace(workspace_id, 1, file_version_id_1)
            .await
            .unwrap();

        backend
            .link_file_to_workspace(workspace_id, 2, file_version_id_2)
            .await
            .unwrap();

        // 3. Create symbols representing a class hierarchy
        let symbols = vec![
            SymbolState {
                symbol_uid: "base_class".to_string(),
                file_version_id: file_version_id_1,
                language: "rust".to_string(),
                name: "BaseClass".to_string(),
                fqn: Some("package::BaseClass".to_string()),
                kind: "class".to_string(),
                signature: Some("class BaseClass".to_string()),
                visibility: Some("public".to_string()),
                def_start_line: 1,
                def_start_char: 0,
                def_end_line: 10,
                def_end_char: 1,
                is_definition: true,
                documentation: Some("Base class documentation".to_string()),
                metadata: None,
            },
            SymbolState {
                symbol_uid: "derived_class".to_string(),
                file_version_id: file_version_id_1,
                language: "rust".to_string(),
                name: "DerivedClass".to_string(),
                fqn: Some("package::DerivedClass".to_string()),
                kind: "class".to_string(),
                signature: Some("class DerivedClass extends BaseClass".to_string()),
                visibility: Some("public".to_string()),
                def_start_line: 15,
                def_start_char: 0,
                def_end_line: 25,
                def_end_char: 1,
                is_definition: true,
                documentation: Some("Derived class documentation".to_string()),
                metadata: None,
            },
            SymbolState {
                symbol_uid: "method_call".to_string(),
                file_version_id: file_version_id_2,
                language: "rust".to_string(),
                name: "methodCall".to_string(),
                fqn: Some("package::methodCall".to_string()),
                kind: "function".to_string(),
                signature: Some("fn methodCall() -> BaseClass".to_string()),
                visibility: Some("public".to_string()),
                def_start_line: 5,
                def_start_char: 0,
                def_end_line: 8,
                def_end_char: 1,
                is_definition: true,
                documentation: None,
                metadata: None,
            },
        ];

        // Store symbols
        backend.store_symbols(&symbols).await.unwrap();

        // 4. Create relationships
        let edges = vec![
            Edge {
                language: "rust".to_string(),
                relation: EdgeRelation::InheritsFrom,
                source_symbol_uid: "derived_class".to_string(),
                target_symbol_uid: "base_class".to_string(),
                anchor_file_version_id: file_version_id_1,
                start_line: Some(15),
                start_char: Some(25),
                confidence: 1.0,
                metadata: Some("{\"inheritance_type\": \"extends\"}".to_string()),
            },
            Edge {
                language: "rust".to_string(),
                relation: EdgeRelation::Instantiates,
                source_symbol_uid: "method_call".to_string(),
                target_symbol_uid: "base_class".to_string(),
                anchor_file_version_id: file_version_id_2,
                start_line: Some(7),
                start_char: Some(12),
                confidence: 0.95,
                metadata: None,
            },
            Edge {
                language: "rust".to_string(),
                relation: EdgeRelation::References,
                source_symbol_uid: "method_call".to_string(),
                target_symbol_uid: "derived_class".to_string(),
                anchor_file_version_id: file_version_id_2,
                start_line: Some(6),
                start_char: Some(8),
                confidence: 0.90,
                metadata: None,
            },
        ];

        // Store edges
        backend.store_edges(&edges).await.unwrap();

        // 5. Test comprehensive queries

        // Test finding all classes
        let base_symbols = backend
            .find_symbol_by_name(workspace_id, "BaseClass")
            .await
            .unwrap();
        assert_eq!(base_symbols.len(), 1);
        assert_eq!(base_symbols[0].kind, "class");

        // Test getting references to BaseClass (should include inheritance and instantiation)
        let base_references = backend
            .get_symbol_references(workspace_id, "base_class")
            .await
            .unwrap();
        assert_eq!(base_references.len(), 2); // inheritance + instantiation

        // Test graph traversal from base class
        let inheritance_paths = backend
            .traverse_graph("base_class", 2, &[EdgeRelation::InheritsFrom])
            .await
            .unwrap();
        // This should be empty since we're looking for outgoing inheritance from base class
        assert!(inheritance_paths.is_empty());

        // Test workspace operations
        let workspaces = backend.list_workspaces(Some(1)).await.unwrap();
        assert!(!workspaces.is_empty());
        assert_eq!(workspaces[0].name, "comprehensive-test");

        // Test file version lookup
        let file_version = backend
            .get_file_version_by_digest("file1_hash")
            .await
            .unwrap();
        assert!(file_version.is_some());
        assert_eq!(file_version.unwrap().size_bytes, 2048);

        // Test analysis progress
        let _analysis_run_id = backend
            .create_analysis_run("test-analyzer", "1.0.0", "rust", "{}")
            .await
            .unwrap();

        let progress = backend.get_analysis_progress(workspace_id).await.unwrap();
        assert_eq!(progress.workspace_id, workspace_id);
    }

    #[tokio::test]
    async fn test_batch_operations_performance() -> Result<(), Box<dyn std::error::Error>> {
        let config = DatabaseConfig {
            temporary: true,
            ..Default::default()
        };

        let backend = SQLiteBackend::new(config).await.unwrap();
        let workspace_id = backend
            .create_workspace("test_workspace", 1, Some("main"))
            .await
            .unwrap();

        // Test batch symbol insertion
        let mut symbols = Vec::new();
        for i in 0..500 {
            symbols.push(SymbolState {
                symbol_uid: format!("symbol_{}", i),
                file_version_id: 1,
                language: "rust".to_string(),
                name: format!("TestSymbol{}", i),
                fqn: Some(format!("test::TestSymbol{}", i)),
                kind: "function".to_string(),
                signature: Some(format!("fn test_function_{}()", i)),
                visibility: Some("public".to_string()),
                def_start_line: i as u32,
                def_start_char: 0,
                def_end_line: i as u32,
                def_end_char: 10,
                is_definition: true,
                documentation: Some(format!("Test function {}", i)),
                metadata: Some("test_metadata".to_string()),
            });
        }

        let start_time = std::time::Instant::now();
        backend.store_symbols(&symbols).await.unwrap();
        let duration = start_time.elapsed();

        println!("Batch stored {} symbols in {:?}", symbols.len(), duration);
        assert!(
            duration.as_millis() < 5000,
            "Batch operation should be fast"
        );

        // Test batch edge insertion
        let mut edges = Vec::new();
        for i in 0..1000 {
            edges.push(Edge {
                source_symbol_uid: format!("symbol_{}", i % 500),
                target_symbol_uid: format!("symbol_{}", (i + 1) % 500),
                relation: crate::database::EdgeRelation::Calls,
                anchor_file_version_id: 1,
                start_line: Some(i as u32),
                start_char: Some(0),
                confidence: 0.9,
                language: "rust".to_string(),
                metadata: None,
            });
        }

        let start_time = std::time::Instant::now();
        backend.store_edges(&edges).await.unwrap();
        let duration = start_time.elapsed();

        println!("Batch stored {} edges in {:?}", edges.len(), duration);
        assert!(
            duration.as_millis() < 10000,
            "Batch edge operation should be fast"
        );

        Ok(())
    }

    #[tokio::test]
    async fn test_database_integrity_validation() -> Result<(), Box<dyn std::error::Error>> {
        let config = DatabaseConfig {
            temporary: true,
            ..Default::default()
        };

        let backend = SQLiteBackend::new(config).await.unwrap();

        // Run integrity check on empty database
        let report = backend.validate_integrity().await.unwrap();
        assert_eq!(report.passed_checks, report.total_checks);
        assert!(report.failed_checks.is_empty());

        // Add some test data and verify integrity
        let workspace_id = backend
            .create_workspace("integrity_test", 1, Some("main"))
            .await
            .unwrap();
        backend
            .link_file_to_workspace(workspace_id, 1, 1)
            .await
            .unwrap();

        let symbol = SymbolState {
            symbol_uid: "test_symbol".to_string(),
            file_version_id: 1,
            language: "rust".to_string(),
            name: "TestSymbol".to_string(),
            fqn: Some("test::TestSymbol".to_string()),
            kind: "function".to_string(),
            signature: Some("fn test()".to_string()),
            visibility: Some("public".to_string()),
            def_start_line: 1,
            def_start_char: 0,
            def_end_line: 5,
            def_end_char: 10,
            is_definition: true,
            documentation: None,
            metadata: None,
        };
        backend.store_symbols(&[symbol]).await.unwrap();

        let report = backend.validate_integrity().await.unwrap();
        assert!(report.passed_checks > 0);
        println!("Integrity report: {:?}", report);

        Ok(())
    }

    #[tokio::test]
    async fn test_performance_optimization() -> Result<(), Box<dyn std::error::Error>> {
        let config = DatabaseConfig {
            temporary: true,
            ..Default::default()
        };

        let backend = SQLiteBackend::new(config).await.unwrap();

        let report = backend.optimize_performance().await.unwrap();
        assert!(!report.optimizations_applied.is_empty());
        assert!(!report.index_recommendations.is_empty());
        assert!(!report.query_stats.is_empty());

        println!("Performance optimization report: {:?}", report);

        // Verify that optimization actually improves something
        assert!(report
            .optimizations_applied
            .iter()
            .any(|opt| opt.contains("PRAGMA")));

        Ok(())
    }

    #[tokio::test]
    async fn test_cleanup_orphaned_data() -> Result<(), Box<dyn std::error::Error>> {
        let config = DatabaseConfig {
            temporary: true,
            ..Default::default()
        };

        let backend = SQLiteBackend::new(config).await.unwrap();

        // Create some data first
        let workspace_id = backend
            .create_workspace("cleanup_test", 1, Some("main"))
            .await
            .unwrap();
        let symbol = SymbolState {
            symbol_uid: "cleanup_test_symbol".to_string(),
            file_version_id: 1,
            language: "rust".to_string(),
            name: "TestSymbol".to_string(),
            fqn: Some("test::TestSymbol".to_string()),
            kind: "function".to_string(),
            signature: None,
            visibility: None,
            def_start_line: 1,
            def_start_char: 0,
            def_end_line: 5,
            def_end_char: 10,
            is_definition: true,
            documentation: None,
            metadata: None,
        };
        backend.store_symbols(&[symbol]).await.unwrap();

        // Run cleanup
        let report = backend.cleanup_orphaned_data().await.unwrap();
        println!("Cleanup report: {:?}", report);

        // Verify cleanup ran without errors
        assert!(report.deleted_records.len() >= 0); // May be zero if no orphaned data

        Ok(())
    }

    #[tokio::test]
    async fn test_real_analysis_progress_tracking() -> Result<(), Box<dyn std::error::Error>> {
        let config = DatabaseConfig {
            temporary: true,
            ..Default::default()
        };

        let backend = SQLiteBackend::new(config).await.unwrap();
        let workspace_id = backend
            .create_workspace("progress_test", 1, Some("main"))
            .await
            .unwrap();

        // Initially should have no progress
        let progress = backend.get_analysis_progress(workspace_id).await.unwrap();
        assert_eq!(progress.analyzed_files, 0);

        // Add some workspace files
        for i in 1..=5 {
            backend
                .link_file_to_workspace(workspace_id, i, i)
                .await
                .unwrap();
        }

        // Queue some files for analysis
        for i in 1..=3 {
            backend.queue_file_analysis(i, "rust", 1).await.unwrap();
        }

        let progress = backend.get_analysis_progress(workspace_id).await.unwrap();

        // Should now have some files tracked
        assert!(progress.total_files >= 0);
        println!("Progress with queued files: {:?}", progress);

        Ok(())
    }

    #[tokio::test]
    async fn test_content_hashing() -> Result<(), Box<dyn std::error::Error>> {
        let config = DatabaseConfig {
            temporary: true,
            ..Default::default()
        };

        let backend = SQLiteBackend::new(config).await.unwrap();

        let content1 = b"fn main() { println!(\"Hello, world!\"); }";
        let content2 = b"fn main() { println!(\"Hello, rust!\"); }";

        let hash1 = backend.compute_content_hash(content1).await;
        let hash2 = backend.compute_content_hash(content2).await;

        assert_ne!(hash1, hash2);
        assert_eq!(hash1.len(), 64); // Blake3 produces 64-char hex strings
        assert_eq!(hash2.len(), 64);

        // Verify consistent hashing
        let hash1_repeat = backend.compute_content_hash(content1).await;
        assert_eq!(hash1, hash1_repeat);

        Ok(())
    }

    #[tokio::test]
    async fn test_transaction_rollback_scenarios() -> Result<(), Box<dyn std::error::Error>> {
        let config = DatabaseConfig {
            temporary: true,
            ..Default::default()
        };

        let backend = SQLiteBackend::new(config).await.unwrap();

        // Test rollback with invalid data
        let invalid_symbols = vec![SymbolState {
            symbol_uid: "valid_symbol".to_string(),
            file_version_id: 1,
            language: "rust".to_string(),
            name: "ValidSymbol".to_string(),
            fqn: None,
            kind: "function".to_string(),
            signature: None,
            visibility: None,
            def_start_line: 1,
            def_start_char: 0,
            def_end_line: 5,
            def_end_char: 10,
            is_definition: true,
            documentation: None,
            metadata: None,
        }];

        // This should succeed normally
        backend.store_symbols(&invalid_symbols).await.unwrap();

        // Verify the symbol was stored
        let symbols = backend.get_symbols_by_file(1, "rust").await.unwrap();
        assert_eq!(symbols.len(), 1);
        assert_eq!(symbols[0].name, "ValidSymbol");

        Ok(())
    }

    #[tokio::test]
    async fn test_error_handling() {
        let config = DatabaseConfig {
            temporary: true,
            ..Default::default()
        };

        let backend = SQLiteBackend::new(config).await.unwrap();

        // Test get non-existent workspace
        let workspace = backend.get_workspace(999999).await.unwrap();
        assert!(workspace.is_none());

        // Test get non-existent file version
        let file_version = backend
            .get_file_version_by_digest("non_existent_hash")
            .await
            .unwrap();
        assert!(file_version.is_none());

        // Test find non-existent symbol
        let symbols = backend
            .find_symbol_by_name(1, "NonExistentSymbol")
            .await
            .unwrap();
        assert!(symbols.is_empty());

        // Test find non-existent FQN
        let symbol = backend
            .find_symbol_by_fqn(1, "non::existent::symbol")
            .await
            .unwrap();
        assert!(symbol.is_none());

        // Test get references for non-existent symbol
        let references = backend
            .get_symbol_references(1, "non_existent_symbol")
            .await
            .unwrap();
        assert!(references.is_empty());

        // Test traverse graph with empty relations
        let paths = backend.traverse_graph("any_symbol", 2, &[]).await.unwrap();
        assert!(paths.is_empty());
    }
}
